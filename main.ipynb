{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. Data Collection**\n",
    "### **1.1. Get the list of Michelin restaurants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "} # user agent is used to simulate that the http request comes from a real web browser, this prevent the server from blocking requests\n",
    "\n",
    "def guide_michelin(): # 2037\n",
    "        links = []\n",
    "        for i in range(1,101): #100\n",
    "            link = \"https://guide.michelin.com/en/it/restaurants/page/{}\".format(i)\n",
    "            try:\n",
    "                response = requests.get(link, headers=headers)\n",
    "            except Exception as e:\n",
    "                print(f\"{e} \\n {link}\")\n",
    "                continue\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                section = soup.find('div', class_=\"row restaurant__list-row js-restaurant__list_items\")\n",
    "                if section:  \n",
    "                    for a_tag in section.find_all('a', href=True):\n",
    "                        href = 'https://guide.michelin.com' + a_tag['href']\n",
    "                        if href not in links and \"/restaurant/\" in href: \n",
    "                            links.append(href)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve page {i}\")    \n",
    "        return links\n",
    "\n",
    "url_set = guide_michelin()\n",
    "print(len(url_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links.txt', 'w') as f:\n",
    "    for url in url_set:\n",
    "        f.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. Crawl Michelin restaurant pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML documents saved successfully.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('pages'):\n",
    "    os.makedirs('pages')\n",
    "\n",
    "with open('links.txt', 'r') as f:\n",
    "    urls = f.read().splitlines()\n",
    "\n",
    "# Create directories and save HTML documents\n",
    "for index, url in enumerate(urls):\n",
    "    page_number = index // 20 + 1\n",
    "    directory = os.path.join('pages', f'page_{page_number}')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            file_path = os.path.join(directory, f'document_{index}.html')\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "print(\"HTML documents saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_paths = [os.path.join('pages', dir) for dir in os.listdir('pages')]\n",
    "len(dir_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3. Parse downloaded pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract restaurant details from HTML content\n",
    "def extract_restaurant_details(content):\n",
    "    \n",
    "    # Extract the restaurant name\n",
    "    name = content.find('h1', class_='data-sheet__title').get_text(strip=True) if content.find('h1', class_='data-sheet__title') else \"\"\n",
    "    \n",
    "    # Extract the first row of basic information\n",
    "    firstRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[0].get_text(strip=True)\n",
    "    #firstRow = content.find(\"div\", class_=\"data-sheet__block--text\").get_text(strip=True)\n",
    "    firstRow_list = [info.strip() for info in firstRow.split(\",\")]\n",
    "\n",
    "    address = \" \".join(firstRow_list[:-3]) if len(firstRow_list) > 3 else \"\"\n",
    "    city = firstRow_list[-3] if len(firstRow_list) > 2 else \"\"\n",
    "    postalCode = firstRow_list[-2] if len(firstRow_list) > 1 else \"\"\n",
    "    country = firstRow_list[-1] if firstRow_list else \"\"\n",
    "\n",
    "    # Extract the second row of basic information\n",
    "    secondRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[1].get_text(strip=True)\n",
    "    #secondRow = content.find(\"div\", class_=\"data-sheet__block--text\").get_text(strip=True)\n",
    "    secondRow_list = [info.strip() for info in secondRow.split(\"·\")]\n",
    "\n",
    "    priceRange = secondRow_list[0] if secondRow_list else \"\"\n",
    "    cuisineType = secondRow_list[1] if len(secondRow_list) > 1 else \"\"\n",
    "\n",
    "    # Extract the description\n",
    "    description = content.find(\"div\", class_=\"data-sheet__description\").get_text(strip=True) if content.find(\"div\", class_=\"data-sheet__description\") else \"\"\n",
    "\n",
    "    # Extract facilities and services\n",
    "    facilitiesServices_div = content.find_all(\"div\", class_=\"col col-12 col-lg-6\")\n",
    "    # facilitiesServices_div = content.find(\"div\", class_=\"col col-12 col-lg-6\")\n",
    "    facilitiesServices = [li.get_text(strip=True) for li in facilitiesServices_div[0].find_all(\"li\")] if facilitiesServices_div else []\n",
    "    # facilitiesServices = [li.get_text(strip=True) for li in facilitiesServices_div.find(\"li\")] if facilitiesServices_div else []\n",
    "\n",
    "    # Extract credit card information\n",
    "    creditCards_div = content.find(\"div\", class_=\"restaurant-details__services--info\")\n",
    "    creditCards = [os.path.basename(img[\"data-src\"]).split(\"-\")[0] for img in creditCards_div.find_all(\"img\")] if creditCards_div else []\n",
    "\n",
    "    # Extract phone number\n",
    "    phoneNumber = content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}).get_text(strip=True) if content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}) else \"\"\n",
    "\n",
    "    # Extract website\n",
    "    website_div = content.find(\"div\", class_=\"collapse__block-item link-item\")\n",
    "    website = website_div.find(\"a\", class_=\"link js-dtm-link\")[\"href\"] if website_div and website_div.find(\"a\", class_=\"link js-dtm-link\") else \"\"\n",
    "\n",
    "    # Return the extracted data as a dictionary\n",
    "    return {\n",
    "        \"restaurantName\": name,\n",
    "        \"address\": address,\n",
    "        \"city\": city,\n",
    "        \"postalCode\": postalCode,\n",
    "        \"country\": country,\n",
    "        \"priceRange\": priceRange,\n",
    "        \"cuisineType\": cuisineType,\n",
    "        \"description\": description,\n",
    "        \"facilitiesServices\": facilitiesServices,\n",
    "        \"creditCards\": creditCards,\n",
    "        \"phoneNumber\": phoneNumber,\n",
    "        \"website\": website\n",
    "    }\n",
    "\n",
    "# Collecting data from all HTML files\n",
    "#folder_paths = [d for d in os.listdir('pages') if os.path.isdir(d) and d.startswith(\"page_\")]\n",
    "dir_paths = [os.path.join('pages', dir) for dir in os.listdir('pages')]\n",
    "\n",
    "data = []\n",
    "for dir in dir_paths:\n",
    "    for html_file in os.listdir(dir):\n",
    "        if html_file.endswith(\".html\"):\n",
    "            with open(os.path.join(dir, html_file), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                restaurant_details = extract_restaurant_details(soup)\n",
    "                data.append(restaurant_details)\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns = [\"restaurantName\", \"address\", \"city\", \"postalCode\", \"country\", \"priceRange\", \"cuisineType\", \"description\", \"facilitiesServices\", \"creditCards\", \"phoneNumber\", \"website\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hydra</td>\n",
       "      <td>via Antonio Mazza 30</td>\n",
       "      <td>Salerno</td>\n",
       "      <td>84121</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Campanian, Contemporary</td>\n",
       "      <td>Situated in the picturesque historic centre of...</td>\n",
       "      <td>[Air conditioning, Restaurant offering vegetar...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 089 995 8437</td>\n",
       "      <td>http://www.ristorantehydra.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gimmi Restaurant</td>\n",
       "      <td>via San Pietro in Lama 23</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>73100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>Despite its location in a Dominican monastery ...</td>\n",
       "      <td>[Air conditioning, Terrace, Wheelchair access]</td>\n",
       "      <td>[amex, maestrocard, mastercard, visa]</td>\n",
       "      <td>+39 0832 700920</td>\n",
       "      <td>https://www.chiostrodeidomenicani.it/ristorante/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Felix Lo Basso home &amp; restaurant</td>\n",
       "      <td>via Carlo Goldoni 36</td>\n",
       "      <td>Milan</td>\n",
       "      <td>20129</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Italian Contemporary, Creative</td>\n",
       "      <td>Brilliant chef Felix Lo Basso’s menu is inspir...</td>\n",
       "      <td>[Air conditioning, Counter dining, Wheelchair ...</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 02 4540 9759</td>\n",
       "      <td>https://www.felixlobassorestaurant.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Acciuga</td>\n",
       "      <td>via Settevalli 217</td>\n",
       "      <td>Perugia</td>\n",
       "      <td>06128</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Contemporary, International</td>\n",
       "      <td>You would never guess that there was a gourmet...</td>\n",
       "      <td>[Air conditioning, Interesting wine list, Terr...</td>\n",
       "      <td>[amex, unionpay, dinersclub, discover, jcb, ma...</td>\n",
       "      <td>+39 339 263 2591</td>\n",
       "      <td>https://www.lacciuga.net/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antiche Sere</td>\n",
       "      <td>via Cenischia 9</td>\n",
       "      <td>Turin</td>\n",
       "      <td>10139</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€</td>\n",
       "      <td>Piedmontese, Classic Cuisine</td>\n",
       "      <td>This renowned osteria situated in a district o...</td>\n",
       "      <td>[Air conditioning, Terrace]</td>\n",
       "      <td>[dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 011 385 4347</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Vintage 1997</td>\n",
       "      <td>piazza Solferino 16/h</td>\n",
       "      <td>Turin</td>\n",
       "      <td>10121</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Italian, Classic Cuisine</td>\n",
       "      <td>The several tasting menus at this restaurant i...</td>\n",
       "      <td>[Air conditioning, Interesting wine list, Rest...</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 011 535948</td>\n",
       "      <td>https://www.vintage1997.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Locanda Margon</td>\n",
       "      <td>via Margone 15</td>\n",
       "      <td>Ravina</td>\n",
       "      <td>38123</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative, Contemporary</td>\n",
       "      <td>This restaurant with views of Trento and the A...</td>\n",
       "      <td>[Air conditioning, Car park, Garden or park, G...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 0461 349401</td>\n",
       "      <td>https://www.locandamargon.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Bon Wei</td>\n",
       "      <td>via Castelvetro 16/18</td>\n",
       "      <td>Milan</td>\n",
       "      <td>20154</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>China on a plate! This attractive restaurant w...</td>\n",
       "      <td>[Air conditioning, Wheelchair access]</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 02 341308</td>\n",
       "      <td>https://www.bon-wei.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Le Lampare al Fortino</td>\n",
       "      <td>via Tiepolo molo Sant'Antonio</td>\n",
       "      <td>Trani</td>\n",
       "      <td>76125</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Mediterranean Cuisine, Modern Cuisine</td>\n",
       "      <td>Built over a medieval church, this old fort th...</td>\n",
       "      <td>[Air conditioning, Great view, Interesting win...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 0883 480308</td>\n",
       "      <td>https://www.lelamparealfortino.it/it/home/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Veneziano</td>\n",
       "      <td>Contrada Arena SS 120 km 187</td>\n",
       "      <td>Randazzo</td>\n",
       "      <td>95036</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Sicilian, Traditional Cuisine</td>\n",
       "      <td>Situated just outside Randazzo, one of the vil...</td>\n",
       "      <td>[Air conditioning, Car park, Garden or park, T...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 095 799 1353</td>\n",
       "      <td>https://www.ristoranteveneziano.it/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1983 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        restaurantName                        address  \\\n",
       "0                                Hydra           via Antonio Mazza 30   \n",
       "1                     Gimmi Restaurant      via San Pietro in Lama 23   \n",
       "2     Felix Lo Basso home & restaurant           via Carlo Goldoni 36   \n",
       "3                            L'Acciuga             via Settevalli 217   \n",
       "4                         Antiche Sere                via Cenischia 9   \n",
       "...                                ...                            ...   \n",
       "1978                      Vintage 1997          piazza Solferino 16/h   \n",
       "1979                    Locanda Margon                 via Margone 15   \n",
       "1980                           Bon Wei          via Castelvetro 16/18   \n",
       "1981             Le Lampare al Fortino  via Tiepolo molo Sant'Antonio   \n",
       "1982                         Veneziano   Contrada Arena SS 120 km 187   \n",
       "\n",
       "          city postalCode country priceRange  \\\n",
       "0      Salerno      84121   Italy         €€   \n",
       "1        Lecce      73100   Italy        €€€   \n",
       "2        Milan      20129   Italy       €€€€   \n",
       "3      Perugia      06128   Italy        €€€   \n",
       "4        Turin      10139   Italy          €   \n",
       "...        ...        ...     ...        ...   \n",
       "1978     Turin      10121   Italy        €€€   \n",
       "1979    Ravina      38123   Italy       €€€€   \n",
       "1980     Milan      20154   Italy         €€   \n",
       "1981     Trani      76125   Italy        €€€   \n",
       "1982  Randazzo      95036   Italy         €€   \n",
       "\n",
       "                                cuisineType  \\\n",
       "0                   Campanian, Contemporary   \n",
       "1                              Contemporary   \n",
       "2            Italian Contemporary, Creative   \n",
       "3               Contemporary, International   \n",
       "4              Piedmontese, Classic Cuisine   \n",
       "...                                     ...   \n",
       "1978               Italian, Classic Cuisine   \n",
       "1979                 Creative, Contemporary   \n",
       "1980                         Chinese, Asian   \n",
       "1981  Mediterranean Cuisine, Modern Cuisine   \n",
       "1982          Sicilian, Traditional Cuisine   \n",
       "\n",
       "                                            description  \\\n",
       "0     Situated in the picturesque historic centre of...   \n",
       "1     Despite its location in a Dominican monastery ...   \n",
       "2     Brilliant chef Felix Lo Basso’s menu is inspir...   \n",
       "3     You would never guess that there was a gourmet...   \n",
       "4     This renowned osteria situated in a district o...   \n",
       "...                                                 ...   \n",
       "1978  The several tasting menus at this restaurant i...   \n",
       "1979  This restaurant with views of Trento and the A...   \n",
       "1980  China on a plate! This attractive restaurant w...   \n",
       "1981  Built over a medieval church, this old fort th...   \n",
       "1982  Situated just outside Randazzo, one of the vil...   \n",
       "\n",
       "                                     facilitiesServices  \\\n",
       "0     [Air conditioning, Restaurant offering vegetar...   \n",
       "1        [Air conditioning, Terrace, Wheelchair access]   \n",
       "2     [Air conditioning, Counter dining, Wheelchair ...   \n",
       "3     [Air conditioning, Interesting wine list, Terr...   \n",
       "4                           [Air conditioning, Terrace]   \n",
       "...                                                 ...   \n",
       "1978  [Air conditioning, Interesting wine list, Rest...   \n",
       "1979  [Air conditioning, Car park, Garden or park, G...   \n",
       "1980              [Air conditioning, Wheelchair access]   \n",
       "1981  [Air conditioning, Great view, Interesting win...   \n",
       "1982  [Air conditioning, Car park, Garden or park, T...   \n",
       "\n",
       "                                            creditCards       phoneNumber  \\\n",
       "0                  [amex, dinersclub, mastercard, visa]  +39 089 995 8437   \n",
       "1                 [amex, maestrocard, mastercard, visa]   +39 0832 700920   \n",
       "2                              [amex, mastercard, visa]  +39 02 4540 9759   \n",
       "3     [amex, unionpay, dinersclub, discover, jcb, ma...  +39 339 263 2591   \n",
       "4                        [dinersclub, mastercard, visa]  +39 011 385 4347   \n",
       "...                                                 ...               ...   \n",
       "1978                           [amex, mastercard, visa]    +39 011 535948   \n",
       "1979               [amex, dinersclub, mastercard, visa]   +39 0461 349401   \n",
       "1980                           [amex, mastercard, visa]     +39 02 341308   \n",
       "1981               [amex, dinersclub, mastercard, visa]   +39 0883 480308   \n",
       "1982               [amex, dinersclub, mastercard, visa]  +39 095 799 1353   \n",
       "\n",
       "                                               website  \n",
       "0                       http://www.ristorantehydra.com  \n",
       "1     https://www.chiostrodeidomenicani.it/ristorante/  \n",
       "2               https://www.felixlobassorestaurant.it/  \n",
       "3                            https://www.lacciuga.net/  \n",
       "4                                                       \n",
       "...                                                ...  \n",
       "1978                      https://www.vintage1997.com/  \n",
       "1979                     https://www.locandamargon.it/  \n",
       "1980                           https://www.bon-wei.it/  \n",
       "1981        https://www.lelamparealfortino.it/it/home/  \n",
       "1982               https://www.ristoranteveneziano.it/  \n",
       "\n",
       "[1983 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (4.67.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize and remove stopwords, then apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply to the description field\n",
    "df['processed_description'] = df['description'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conjunctive Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create the Index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = {}\n",
    "inverted_index = defaultdict(list)\n",
    "term_id_counter = 0\n",
    "\n",
    "for doc_id, description in enumerate(df['processed_description']):\n",
    "    for word in description.split():\n",
    "        # Map each unique word to a term_id\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = term_id_counter\n",
    "            term_id_counter += 1\n",
    "        term_id = vocabulary[word]\n",
    "        inverted_index[term_id].append(doc_id)\n",
    "\n",
    "# Save the vocabulary to a CSV file\n",
    "pd.DataFrame(list(vocabulary.items()), columns=['term', 'term_id']).to_csv('vocabulary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('inverted_index.json', 'w') as f:\n",
    "    json.dump(inverted_index, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    query = query.lower()\n",
    "    query = query.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = [stemmer.stem(word) for word in query.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def conjunctive_query(query):\n",
    "    query_terms = preprocess_query(query)\n",
    "    term_ids = [vocabulary.get(term) for term in query_terms if term in vocabulary]\n",
    "\n",
    "    if not term_ids:\n",
    "        return pd.DataFrame(columns=[\"restaurantName\", \"address\", \"description\", \"website\"])\n",
    "\n",
    "    # Start with the document list for the first term, then intersect with others\n",
    "    matching_docs = set(inverted_index[term_ids[0]])\n",
    "    for term_id in term_ids[1:]:\n",
    "        matching_docs &= set(inverted_index[term_id])\n",
    "\n",
    "    results = df.loc[list(matching_docs), [\"restaurantName\", \"address\", \"description\", \"website\"]]\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_index = defaultdict(list)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Loop over each term (feature) in the TF-IDF matrix\n",
    "for term_id, term in enumerate(feature_names):\n",
    "    # Get non-zero document indices and the corresponding scores for this term\n",
    "    doc_indices = tfidf_matrix[:, term_id].nonzero()[0]\n",
    "    scores = tfidf_matrix[:, term_id].data\n",
    "    \n",
    "    # Append each document ID and score to the tfidf_index dictionary \n",
    "    for doc_id, score in zip(doc_indices, scores):\n",
    "        tfidf_index[term].append((doc_id, score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ranked Search Engine with TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def ranked_query(query, top_k=5):\n",
    "    query_vec = tfidf_vectorizer.transform([preprocess_text(query)])\n",
    "    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    top_doc_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = df.loc[top_doc_indices, ['restaurantName', 'address', 'description', 'website']]\n",
    "    results['similarity_score'] = cosine_similarities[top_doc_indices]\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      restaurantName                         address  \\\n",
      "111  Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
      "\n",
      "                                           description website  \n",
      "111  This pleasant, warmly decorated restaurant is ...          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Osteria Taviani</td>\n",
       "      <td>piazza Vittorio Emanuele II 28</td>\n",
       "      <td>This pleasant, warmly decorated restaurant is ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      restaurantName                         address  \\\n",
       "111  Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
       "\n",
       "                                           description website  \n",
       "111  This pleasant, warmly decorated restaurant is ...          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       restaurantName                         address  \\\n",
      "111   Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
      "238          Menzaghi             via San Giovanni 74   \n",
      "1497       SaleGrosso              viale II Giugno 15   \n",
      "1673   Marsupino 1901               via Roma Serra 20   \n",
      "1818   Lio Pellegrini               via San Tomaso 47   \n",
      "\n",
      "                                            description  \\\n",
      "111   This pleasant, warmly decorated restaurant is ...   \n",
      "238   Once you’ve found the car park, make your way ...   \n",
      "1497  One of the town’s authentic favourites, this f...   \n",
      "1673  The Marsupino family has been running this tra...   \n",
      "1818  Despite its location in the town centre, the a...   \n",
      "\n",
      "                                 website  similarity_score  \n",
      "111                                               0.302989  \n",
      "238   https://www.ristorantemenzaghi.it/          0.221025  \n",
      "1497  http://www.ristorantesalegrosso.it          0.203840  \n",
      "1673  https://www.trattoriamarsupino.it/          0.174293  \n",
      "1818  https://www.liopellegrini.it/site/          0.172042  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Osteria Taviani</td>\n",
       "      <td>piazza Vittorio Emanuele II 28</td>\n",
       "      <td>This pleasant, warmly decorated restaurant is ...</td>\n",
       "      <td></td>\n",
       "      <td>0.302989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Menzaghi</td>\n",
       "      <td>via San Giovanni 74</td>\n",
       "      <td>Once you’ve found the car park, make your way ...</td>\n",
       "      <td>https://www.ristorantemenzaghi.it/</td>\n",
       "      <td>0.221025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>SaleGrosso</td>\n",
       "      <td>viale II Giugno 15</td>\n",
       "      <td>One of the town’s authentic favourites, this f...</td>\n",
       "      <td>http://www.ristorantesalegrosso.it</td>\n",
       "      <td>0.203840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Marsupino 1901</td>\n",
       "      <td>via Roma Serra 20</td>\n",
       "      <td>The Marsupino family has been running this tra...</td>\n",
       "      <td>https://www.trattoriamarsupino.it/</td>\n",
       "      <td>0.174293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Lio Pellegrini</td>\n",
       "      <td>via San Tomaso 47</td>\n",
       "      <td>Despite its location in the town centre, the a...</td>\n",
       "      <td>https://www.liopellegrini.it/site/</td>\n",
       "      <td>0.172042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       restaurantName                         address  \\\n",
       "111   Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
       "238          Menzaghi             via San Giovanni 74   \n",
       "1497       SaleGrosso              viale II Giugno 15   \n",
       "1673   Marsupino 1901               via Roma Serra 20   \n",
       "1818   Lio Pellegrini               via San Tomaso 47   \n",
       "\n",
       "                                            description  \\\n",
       "111   This pleasant, warmly decorated restaurant is ...   \n",
       "238   Once you’ve found the car park, make your way ...   \n",
       "1497  One of the town’s authentic favourites, this f...   \n",
       "1673  The Marsupino family has been running this tra...   \n",
       "1818  Despite its location in the town centre, the a...   \n",
       "\n",
       "                                 website  similarity_score  \n",
       "111                                               0.302989  \n",
       "238   https://www.ristorantemenzaghi.it/          0.221025  \n",
       "1497  http://www.ristorantesalegrosso.it          0.203840  \n",
       "1673  https://www.trattoriamarsupino.it/          0.174293  \n",
       "1818  https://www.liopellegrini.it/site/          0.172042  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the conjunctive query\n",
    "query = \"This pleasant, warmly decorated restaurant is ...\"\n",
    "conjunctive_results = conjunctive_query(query)\n",
    "print(conjunctive_results)\n",
    "display(conjunctive_results)\n",
    "# Test the ranked query\n",
    "ranked_results = ranked_query(query, top_k=5)\n",
    "print(ranked_results)\n",
    "display(ranked_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a New Score!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(query, tfidf_vectorizer, tfidf_matrix):\n",
    "    # Convert the query into a TF-IDF vector\n",
    "    query_tfidf = tfidf_vectorizer.transform([query])\n",
    "    \n",
    "     # Compute cosine similarity between the query vector and all document vectors\n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    #Return similarity scores for all documents\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for custom ranking. \n",
    "def custom_scoring(query, df, tfidf_vectorizer, tfidf_matrix, top_k=5, cuisine_preferences=None, service_preferences=None, price_preferences=None):\n",
    "    # Define differents weights for description, cuisine, facilities and price.\n",
    "    DESCRIPTION_WEIGHT = 0.5\n",
    "    CUISINE_WEIGHT = 0.2\n",
    "    FACILITIES_WEIGHT = 0.2\n",
    "    PRICE_WEIGHT = 0.3\n",
    "\n",
    "    # Calculate cosine similarities between the query and all descriptions\n",
    "    cosine_similarities = calculate_cosine_similarity(query, tfidf_vectorizer, tfidf_matrix)\n",
    "    top_k_restaurants = []\n",
    "\n",
    "    # Iterate over all documents and calculate the custom score for each\n",
    "    for doc_id, cosine_score in enumerate(cosine_similarities):\n",
    "        # Score based on description similarity\n",
    "        description_score = cosine_score * DESCRIPTION_WEIGHT\n",
    "\n",
    "        # Score for matching \"cuisineType\"\n",
    "        cuisine_score = 0\n",
    "        if 'cuisineType' in df.columns and cuisine_preferences:\n",
    "            for pref in cuisine_preferences:\n",
    "                if pref.lower() in df.loc[doc_id, 'cuisineType'].lower():\n",
    "                    cuisine_score += CUISINE_WEIGHT\n",
    "\n",
    "        # Score for matching \"facilitiesServices\"\n",
    "        facilities_score = 0\n",
    "        if 'facilitiesServices' in df.columns and service_preferences:\n",
    "            facilities = df.loc[doc_id, 'facilitiesServices']\n",
    "            if isinstance(facilities, list):\n",
    "                for service in service_preferences:\n",
    "                    if any(service.lower() == facility.lower() for facility in facilities):\n",
    "                        facilities_score += FACILITIES_WEIGHT\n",
    "\n",
    "        # Score for matching \"priceRange\"\n",
    "        price_score = 0\n",
    "        if 'priceRange' in df.columns and price_preferences:\n",
    "            price_range = df.loc[doc_id, 'priceRange']\n",
    "            for price in price_preferences:\n",
    "                if price in price_range:\n",
    "                    price_score += PRICE_WEIGHT\n",
    "\n",
    "        # Calculate the final custom score\n",
    "        final_score = description_score + cuisine_score + facilities_score + price_score\n",
    "\n",
    "        # Add to the heap to maintain top-k results\n",
    "        if len(top_k_restaurants) < top_k:\n",
    "            heapq.heappush(top_k_restaurants, (final_score, doc_id))\n",
    "        else:\n",
    "            heapq.heappushpop(top_k_restaurants, (final_score, doc_id))\n",
    "\n",
    "    # Sort the top-k results by score in descending order\n",
    "    top_k_restaurants = sorted(top_k_restaurants, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Prepare the final output\n",
    "    results = []\n",
    "    for score, doc_id in top_k_restaurants:\n",
    "        results.append({\n",
    "            \"restaurantName\": df.loc[doc_id, \"restaurantName\"],\n",
    "            \"address\": df.loc[doc_id, \"address\"],\n",
    "            \"description\": df.loc[doc_id, \"description\"],\n",
    "            \"website\": df.loc[doc_id, \"website\"],\n",
    "            \"custom_score\": round(score, 3)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "      <th>custom_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'Osteria di Santa Marina</td>\n",
       "      <td>campo Santa Marina sestiere di Castello 5911</td>\n",
       "      <td>This classy inn is managed by young profession...</td>\n",
       "      <td>https://osteriadisantamarina.com/</td>\n",
       "      <td>1.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Lampare al Fortino</td>\n",
       "      <td>via Tiepolo molo Sant'Antonio</td>\n",
       "      <td>Built over a medieval church, this old fort th...</td>\n",
       "      <td>https://www.lelamparealfortino.it/it/home/</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Essenza Bistrot</td>\n",
       "      <td>via delle Terme 8/A</td>\n",
       "      <td>A welcoming and original bistro-restaurant in ...</td>\n",
       "      <td>https://www.essenzabistrot.it</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jamantè</td>\n",
       "      <td>via San Vito 97</td>\n",
       "      <td>Located not far from the historic centre and t...</td>\n",
       "      <td>https://www.jamanteristorante.com</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Livello 1</td>\n",
       "      <td>via Duccio di Buoninsegna 25</td>\n",
       "      <td>Situated in the suburbs off the main tourist t...</td>\n",
       "      <td>http://www.ristorantelivello1.it</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              restaurantName                                       address  \\\n",
       "0  L'Osteria di Santa Marina  campo Santa Marina sestiere di Castello 5911   \n",
       "1      Le Lampare al Fortino                 via Tiepolo molo Sant'Antonio   \n",
       "2            Essenza Bistrot                           via delle Terme 8/A   \n",
       "3                    Jamantè                               via San Vito 97   \n",
       "4                  Livello 1                  via Duccio di Buoninsegna 25   \n",
       "\n",
       "                                         description  \\\n",
       "0  This classy inn is managed by young profession...   \n",
       "1  Built over a medieval church, this old fort th...   \n",
       "2  A welcoming and original bistro-restaurant in ...   \n",
       "3  Located not far from the historic centre and t...   \n",
       "4  Situated in the suburbs off the main tourist t...   \n",
       "\n",
       "                                      website  custom_score  \n",
       "0           https://osteriadisantamarina.com/         1.011  \n",
       "1  https://www.lelamparealfortino.it/it/home/         0.981  \n",
       "2               https://www.essenzabistrot.it         0.976  \n",
       "3           https://www.jamanteristorante.com         0.967  \n",
       "4            http://www.ristorantelivello1.it         0.965  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define the query and the user's preferences\n",
    "query = \"seafood\"\n",
    "cuisine_preferences = [\"Modern Cuisine\"]\n",
    "service_preferences = [\"Terrace\", \"Air conditioning\"]   \n",
    "price_preferences = [\"€€€\"]\n",
    "top_k = 5\n",
    "\n",
    "# Call the custom scoring function and display the results\n",
    "results_df = custom_scoring(query, df, tfidf_vectorizer, tfidf_matrix, top_k, cuisine_preferences, service_preferences,  price_preferences)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Bonus \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'creditCards'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'creditCards'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Ricerca e filtri\u001b[39;00m\n\u001b[1;32m     84\u001b[0m search_results \u001b[38;5;241m=\u001b[39m advanced_search_multi_field(df, vocabularies, inverted_indexes, queries)\n\u001b[0;32m---> 85\u001b[0m filtered_results \u001b[38;5;241m=\u001b[39m \u001b[43mapply_filters\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfacilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredit_cards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Output dei risultati\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtered_results\u001b[38;5;241m.\u001b[39mempty:\n",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m, in \u001b[0;36mapply_filters\u001b[0;34m(data, price_range, region, facilities, credit_cards)\u001b[0m\n\u001b[1;32m     61\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacilitiesServices\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28many\u001b[39m(f \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m facilities))]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m credit_cards:\n\u001b[0;32m---> 63\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreditCards\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28many\u001b[39m(cc \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m credit_cards))]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'creditCards'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Funzione per preprocessare il testo (es. tokenizzazione e normalizzazione)\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return []\n",
    "    # Tokenizzazione semplice e conversione in minuscolo\n",
    "    return [token.strip().lower() for token in text.split()]\n",
    "\n",
    "# Funzione per creare vocabolari e indici invertiti\n",
    "def create_vocabularies_and_indexes(data, fields):\n",
    "    vocabularies = {field: {} for field in fields}\n",
    "    inverted_indexes = {field: defaultdict(set) for field in fields}\n",
    "    term_ids = {field: 0 for field in fields}\n",
    "    \n",
    "    for doc_id, row in data.iterrows():\n",
    "        for field in fields:\n",
    "            tokens = preprocess_text(row[field])\n",
    "            for token in tokens:\n",
    "                if token not in vocabularies[field]:\n",
    "                    vocabularies[field][token] = term_ids[field]\n",
    "                    term_ids[field] += 1\n",
    "                term_id = vocabularies[field][token]\n",
    "                inverted_indexes[field][term_id].add(doc_id)\n",
    "    \n",
    "    return vocabularies, inverted_indexes\n",
    "\n",
    "# Funzione per eseguire una query congiunta\n",
    "def conjunctive_query(query, vocabulary, inverted_index):\n",
    "    query_tokens = preprocess_text(query)\n",
    "    query_term_ids = [vocabulary[token] for token in query_tokens if token in vocabulary]\n",
    "    \n",
    "    if not query_term_ids:\n",
    "        return set()\n",
    "    \n",
    "    doc_lists = [inverted_index[tid] for tid in query_term_ids if tid in inverted_index]\n",
    "    return set.intersection(*doc_lists) if doc_lists else set()\n",
    "\n",
    "# Funzione avanzata per ricerca multi-campo\n",
    "def advanced_search_multi_field(data, vocabularies, inverted_indexes, queries):\n",
    "    results = set(data.index)\n",
    "    \n",
    "    for field, query in queries.items():\n",
    "        if query:\n",
    "            field_vocab = vocabularies[field]\n",
    "            field_index = inverted_indexes[field]\n",
    "            field_results = conjunctive_query(query, field_vocab, field_index)\n",
    "            results.intersection_update(field_results)\n",
    "    \n",
    "    return data.loc[list(results), ['restaurantName', 'city', 'cuisineType', 'priceRange', \n",
    "                                    'creditCards', 'facilitiesServices', 'country', 'website']]\n",
    "\n",
    "# Funzione per applicare filtri\n",
    "def apply_filters(data, price_range=None, region=None, facilities=None, credit_cards=None):\n",
    "    if price_range:\n",
    "        data = data[data['priceRange'].isin(price_range)]\n",
    "    if region:\n",
    "        data = data[data['country'].isin(region)]\n",
    "    if facilities:\n",
    "        data = data[data['facilitiesServices'].apply(lambda x: any(f in x for f in facilities))]\n",
    "    if credit_cards:\n",
    "        data = data[data['creditCards'].apply(lambda x: any(cc in x for cc in credit_cards))]\n",
    "    return data\n",
    "\n",
    "# Creazione degli indici dai dati estratti\n",
    "fields_to_index = ['restaurantName', 'city', 'cuisineType']\n",
    "vocabularies, inverted_indexes = create_vocabularies_and_indexes(df, fields_to_index)\n",
    "\n",
    "# Input dell'utente\n",
    "queries = {\n",
    "    'restaurantName': input(\"Inserisci il nome del ristorante: \").strip(),\n",
    "    'city': input(\"Inserisci la città: \").strip(),\n",
    "    'cuisineType': input(\"Inserisci il tipo di cucina: \").strip()\n",
    "}\n",
    "\n",
    "# Filtri aggiuntivi\n",
    "price_range = input(\"Inserisci la fascia di prezzo (es. €, €€, separati da virgola): \").strip().split(\",\")\n",
    "region = input(\"Inserisci il paese o regione (es. Italia, Francia): \").strip().split(\",\")\n",
    "facilities = input(\"Inserisci i servizi (es. WiFi, Accessibile): \").strip().split(\",\")\n",
    "credit_cards = input(\"Inserisci le carte di credito accettate (es. Visa, MasterCard): \").strip().split(\",\")\n",
    "\n",
    "# Ricerca e filtri\n",
    "search_results = advanced_search_multi_field(df, vocabularies, inverted_indexes, queries)\n",
    "filtered_results = apply_filters(search_results, price_range, region, facilities, credit_cards)\n",
    "\n",
    "# Output dei risultati\n",
    "if filtered_results.empty:\n",
    "    print(\"Nessun risultato trovato.\")\n",
    "else:\n",
    "    print(\"Risultati trovati:\")\n",
    "    print(filtered_results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [restaurantName, address, cuisineType, priceRange, website]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by tokenizing and normalizing it.\n",
    "    Example implementation: Convert text to lowercase and split on spaces.\n",
    "    \"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "def build_vocabulary_and_inverted_indexes(df):\n",
    "    \"\"\"\n",
    "    Builds vocabularies and inverted indexes for the fields: restaurantName, city, and cuisineType.\n",
    "    \"\"\"\n",
    "    vocab = {\n",
    "        'restaurantName': {},\n",
    "        'city': {},\n",
    "        'cuisineType': {}\n",
    "    }\n",
    "    \n",
    "    inverted_index = {\n",
    "        'restaurantName': defaultdict(set),\n",
    "        'city': defaultdict(set),\n",
    "        'cuisineType': defaultdict(set)\n",
    "    }\n",
    "    \n",
    "    term_counter = {\n",
    "        'restaurantName': 0,\n",
    "        'city': 0,\n",
    "        'cuisineType': 0\n",
    "    }\n",
    "\n",
    "    # Iterate through each row in the dataset\n",
    "    for record_id, row in df.iterrows():\n",
    "        for field in ['restaurantName', 'city', 'cuisineType']:\n",
    "            tokens = preprocess_text(row[field])  # Tokenize the field value\n",
    "\n",
    "            for token in tokens:\n",
    "                # If the token doesn't exist in the vocabulary, add it and assign a new term ID\n",
    "                if token not in vocab[field]:\n",
    "                    vocab[field][token] = term_counter[field]\n",
    "                    term_counter[field] += 1\n",
    "\n",
    "                # Get the term ID for the token and add the current record to the inverted index\n",
    "                term_id = vocab[field][token]\n",
    "                inverted_index[field][term_id].add(record_id)\n",
    "\n",
    "    return vocab, inverted_index\n",
    "\n",
    "def conjunctive_query(query, vocab, inverted_index):\n",
    "    \"\"\"\n",
    "    Performs a conjunctive query to retrieve documents containing all terms from the query.\n",
    "    \"\"\"\n",
    "    # Preprocess the query text and convert it to term IDs using the vocabulary\n",
    "    query_tokens = preprocess_text(query)\n",
    "    query_term_ids = [vocab.get(token) for token in query_tokens if token in vocab]\n",
    "\n",
    "    # If no terms from the query are found in the vocabulary, return an empty set\n",
    "    if not query_term_ids:\n",
    "        return set()\n",
    "\n",
    "    # Find document IDs containing all term IDs from the query\n",
    "    doc_sets = [inverted_index[term_id] for term_id in query_term_ids if term_id in inverted_index]\n",
    "\n",
    "    # If doc_sets are not empty, find the intersection of all document sets\n",
    "    if doc_sets:\n",
    "        matching_docs = set.intersection(*doc_sets)\n",
    "    else:\n",
    "        matching_docs = set()\n",
    "\n",
    "    # Return the set of matching document indices\n",
    "    return matching_docs\n",
    "\n",
    "def advanced_search_with_filters(data, name_filter='', city_filter='', cuisine_filter=''):\n",
    "    \"\"\"\n",
    "    Performs an advanced search with filters on restaurant name, city, and cuisine type.\n",
    "    \"\"\"\n",
    "    # Generate vocabularies and inverted indexes for each field\n",
    "    vocab, inverted_idx = build_vocabulary_and_inverted_indexes(data)\n",
    "    \n",
    "    # Start with a set containing all document indices\n",
    "    matching_docs = set(data.index)\n",
    "\n",
    "    # Search by `restaurantName` if a `name_filter` is provided\n",
    "    if name_filter:\n",
    "        name_vocab, name_inv_idx = vocab['restaurantName'], inverted_idx['restaurantName']\n",
    "        name_results = conjunctive_query(name_filter, name_vocab, name_inv_idx)\n",
    "        matching_docs.intersection_update(name_results)\n",
    "\n",
    "    # Search by `city` if a `city_filter` is provided\n",
    "    if city_filter:\n",
    "        city_vocab, city_inv_idx = vocab['city'], inverted_idx['city']\n",
    "        city_results = conjunctive_query(city_filter, city_vocab, city_inv_idx)\n",
    "        matching_docs.intersection_update(city_results)\n",
    "\n",
    "    # Search by `cuisineType` if a `cuisine_filter` is provided\n",
    "    if cuisine_filter:\n",
    "        cuisine_vocab, cuisine_inv_idx = vocab['cuisineType'], inverted_idx['cuisineType']\n",
    "        cuisine_results = conjunctive_query(cuisine_filter, cuisine_vocab, cuisine_inv_idx)\n",
    "        matching_docs.intersection_update(cuisine_results)\n",
    "\n",
    "    # Return the filtered data with the relevant columns\n",
    "    filtered_restaurants = data.loc[list(matching_docs), ['restaurantName', 'address', 'cuisineType', 'priceRange', 'website']]\n",
    "    return filtered_restaurants\n",
    "\n",
    "\n",
    "# Prompt user for search filters\n",
    "name_filter = input(\"Enter restaurant name to search: \")\n",
    "city_filter = input(\"Enter city to search: \")\n",
    "cuisine_filter = input(\"Enter cuisine type to search: \")\n",
    "\n",
    "# Execute the advanced search with filters\n",
    "filtered_results = advanced_search_with_filters(data, name_filter, city_filter, cuisine_filter)\n",
    "\n",
    "# Display the filtered results\n",
    "print(filtered_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    restaurantName                            address       city priceRange  \\\n",
      "358           Dama  Via Mulino località San Gaudenzio  Cervesina        €€€   \n",
      "\n",
      "        cuisineType                          website  \n",
      "358  Modern Cuisine  https://www.hcsg.it/ristorante/  \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def preprocess_text_case_insensitive(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by converting it to lowercase and splitting it into tokens.\n",
    "    \"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "\n",
    "def build_vocabulary_and_inverted_indexes_case_insensitive(df):\n",
    "    \"\"\"\n",
    "    Builds vocabularies and inverted indexes for fields in the dataset, considering case insensitivity.\n",
    "    \"\"\"\n",
    "    vocab = {\n",
    "        'restaurantName': {},\n",
    "        'city': {},\n",
    "        'cuisineType': {}\n",
    "    }\n",
    "    \n",
    "    inverted_index = {\n",
    "        'restaurantName': defaultdict(set),\n",
    "        'city': defaultdict(set),\n",
    "        'cuisineType': defaultdict(set)\n",
    "    }\n",
    "    \n",
    "    term_counter = {\n",
    "        'restaurantName': 0,\n",
    "        'city': 0,\n",
    "        'cuisineType': 0\n",
    "    }\n",
    "\n",
    "    for record_id, row in df.iterrows():\n",
    "        for field in ['restaurantName', 'city', 'cuisineType']:\n",
    "            tokens = preprocess_text_case_insensitive(row[field]) if pd.notnull(row[field]) else []\n",
    "\n",
    "            for token in tokens:\n",
    "                if token not in vocab[field]:\n",
    "                    vocab[field][token] = term_counter[field]\n",
    "                    term_counter[field] += 1\n",
    "\n",
    "                term_id = vocab[field][token]\n",
    "                inverted_index[field][term_id].add(record_id)\n",
    "\n",
    "    return vocab, inverted_index\n",
    "\n",
    "\n",
    "def conjunctive_query_case_insensitive(query, vocab, inverted_index):\n",
    "    \"\"\"\n",
    "    Performs a conjunctive query that is case-insensitive.\n",
    "    \"\"\"\n",
    "    query_tokens = preprocess_text_case_insensitive(query)\n",
    "    query_term_ids = [vocab.get(token) for token in query_tokens if token in vocab]\n",
    "\n",
    "    if not query_term_ids:\n",
    "        return set()\n",
    "\n",
    "    doc_sets = [inverted_index[term_id] for term_id in query_term_ids if term_id in inverted_index]\n",
    "\n",
    "    return set.intersection(*doc_sets) if doc_sets else set()\n",
    "\n",
    "\n",
    "def advanced_search_with_filters_case_insensitive(data, name_filter='', city_filter='', cuisine_filter=''):\n",
    "    \"\"\"\n",
    "    Performs an advanced search with filters on restaurant name, city, and cuisine type.\n",
    "    Search is case-insensitive.\n",
    "    \"\"\"\n",
    "    vocab, inverted_idx = build_vocabulary_and_inverted_indexes_case_insensitive(data)\n",
    "    matching_docs = set(data.index)\n",
    "\n",
    "    if name_filter:\n",
    "        name_vocab, name_inv_idx = vocab['restaurantName'], inverted_idx['restaurantName']\n",
    "        name_results = conjunctive_query_case_insensitive(name_filter, name_vocab, name_inv_idx)\n",
    "        matching_docs.intersection_update(name_results)\n",
    "\n",
    "    if city_filter:\n",
    "        city_vocab, city_inv_idx = vocab['city'], inverted_idx['city']\n",
    "        city_results = conjunctive_query_case_insensitive(city_filter, city_vocab, city_inv_idx)\n",
    "        matching_docs.intersection_update(city_results)\n",
    "\n",
    "    if cuisine_filter:\n",
    "        cuisine_vocab, cuisine_inv_idx = vocab['cuisineType'], inverted_idx['cuisineType']\n",
    "        cuisine_results = conjunctive_query_case_insensitive(cuisine_filter, cuisine_vocab, cuisine_inv_idx)\n",
    "        matching_docs.intersection_update(cuisine_results)\n",
    "\n",
    "    filtered_restaurants = data.loc[list(matching_docs), ['restaurantName', 'address', 'city', 'priceRange', 'cuisineType', 'website']]\n",
    "    return filtered_restaurants\n",
    "\n",
    "\n",
    "# Esegui il processo per estrarre i dati dai file HTML\n",
    "def extract_restaurant_details(content):\n",
    "    \"\"\"\n",
    "    Extracts details about a restaurant from the HTML content.\n",
    "    \"\"\"\n",
    "    name = content.find('h1', class_='data-sheet__title').get_text(strip=True) if content.find('h1', class_='data-sheet__title') else \"\"\n",
    "    firstRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[0].get_text(strip=True)\n",
    "    firstRow_list = [info.strip() for info in firstRow.split(\",\")]\n",
    "\n",
    "    address = \" \".join(firstRow_list[:-3]) if len(firstRow_list) > 3 else \"\"\n",
    "    city = firstRow_list[-3] if len(firstRow_list) > 2 else \"\"\n",
    "    postalCode = firstRow_list[-2] if len(firstRow_list) > 1 else \"\"\n",
    "    country = firstRow_list[-1] if firstRow_list else \"\"\n",
    "\n",
    "    secondRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[1].get_text(strip=True)\n",
    "    secondRow_list = [info.strip() for info in secondRow.split(\"·\")]\n",
    "\n",
    "    priceRange = secondRow_list[0] if secondRow_list else \"\"\n",
    "    cuisineType = secondRow_list[1] if len(secondRow_list) > 1 else \"\"\n",
    "\n",
    "    description = content.find(\"div\", class_=\"data-sheet__description\").get_text(strip=True) if content.find(\"div\", class_=\"data-sheet__description\") else \"\"\n",
    "    facilitiesServices_div = content.find_all(\"div\", class_=\"col col-12 col-lg-6\")\n",
    "    facilitiesServices = [li.get_text(strip=True) for li in facilitiesServices_div[0].find_all(\"li\")] if facilitiesServices_div else []\n",
    "    creditCards_div = content.find(\"div\", class_=\"restaurant-details__services--info\")\n",
    "    creditCards = [os.path.basename(img[\"data-src\"]).split(\"-\")[0] for img in creditCards_div.find_all(\"img\")] if creditCards_div else []\n",
    "    phoneNumber = content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}).get_text(strip=True) if content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}) else \"\"\n",
    "    website_div = content.find(\"div\", class_=\"collapse__block-item link-item\")\n",
    "    website = website_div.find(\"a\", class_=\"link js-dtm-link\")[\"href\"] if website_div and website_div.find(\"a\", class_=\"link js-dtm-link\") else \"\"\n",
    "\n",
    "    return {\n",
    "        \"restaurantName\": name,\n",
    "        \"address\": address,\n",
    "        \"city\": city,\n",
    "        \"postalCode\": postalCode,\n",
    "        \"country\": country,\n",
    "        \"priceRange\": priceRange,\n",
    "        \"cuisineType\": cuisineType,\n",
    "        \"description\": description,\n",
    "        \"facilitiesServices\": facilitiesServices,\n",
    "        \"creditCards\": creditCards,\n",
    "        \"phoneNumber\": phoneNumber,\n",
    "        \"website\": website\n",
    "    }\n",
    "\n",
    "\n",
    "# Carica i dati\n",
    "dir_paths = [os.path.join('pages', dir) for dir in os.listdir('pages')]\n",
    "data = []\n",
    "for dir in dir_paths:\n",
    "    for html_file in os.listdir(dir):\n",
    "        if html_file.endswith(\".html\"):\n",
    "            with open(os.path.join(dir, html_file), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                restaurant_details = extract_restaurant_details(soup)\n",
    "                data.append(restaurant_details)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filtri di esempio\n",
    "name_filter = input(\"Enter restaurant name: \")\n",
    "city_filter = input(\"Enter city: \")\n",
    "cuisine_filter = input(\"Enter cuisine type: \")\n",
    "\n",
    "filtered_results = advanced_search_with_filters_case_insensitive(df, name_filter, city_filter, cuisine_filter)\n",
    "print(filtered_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Dama</td>\n",
       "      <td>Via Mulino località San Gaudenzio</td>\n",
       "      <td>Cervesina</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine</td>\n",
       "      <td>https://www.hcsg.it/ristorante/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    restaurantName                            address       city priceRange  \\\n",
       "358           Dama  Via Mulino località San Gaudenzio  Cervesina        €€€   \n",
       "\n",
       "        cuisineType                          website  \n",
       "358  Modern Cuisine  https://www.hcsg.it/ristorante/  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     restaurantName         address      city priceRange  \\\n",
      "356  O Me O Il Mare  Via Roma 45/47  Gragnano       €€€€   \n",
      "\n",
      "                              cuisineType                website  \n",
      "356  Italian Contemporary, Modern Cuisine  http://omeoilmare.com  \n"
     ]
    }
   ],
   "source": [
    "def advanced_search_with_filters_enhanced(data, name_filter='', city_filter='', cuisine_filter='', \n",
    "                                          price_range_filter=None, region_filter=None, \n",
    "                                          credit_card_filter=None, facilities_filter=None):\n",
    "    \"\"\"\n",
    "    Performs an advanced search with additional filters for price range, region, credit cards, and facilities.\n",
    "    \"\"\"\n",
    "    vocab, inverted_idx = build_vocabulary_and_inverted_indexes_case_insensitive(data)\n",
    "    matching_docs = set(data.index)\n",
    "\n",
    "    # Filtri base\n",
    "    if name_filter:\n",
    "        name_vocab, name_inv_idx = vocab['restaurantName'], inverted_idx['restaurantName']\n",
    "        name_results = conjunctive_query_case_insensitive(name_filter, name_vocab, name_inv_idx)\n",
    "        matching_docs.intersection_update(name_results)\n",
    "\n",
    "    if city_filter:\n",
    "        city_vocab, city_inv_idx = vocab['city'], inverted_idx['city']\n",
    "        city_results = conjunctive_query_case_insensitive(city_filter, city_vocab, city_inv_idx)\n",
    "        matching_docs.intersection_update(city_results)\n",
    "\n",
    "    if cuisine_filter:\n",
    "        cuisine_vocab, cuisine_inv_idx = vocab['cuisineType'], inverted_idx['cuisineType']\n",
    "        cuisine_results = conjunctive_query_case_insensitive(cuisine_filter, cuisine_vocab, cuisine_inv_idx)\n",
    "        matching_docs.intersection_update(cuisine_results)\n",
    "\n",
    "    # Filtro per fascia di prezzo\n",
    "    if price_range_filter:\n",
    "        price_docs = set(data[data['priceRange'].isin(price_range_filter)].index)\n",
    "        matching_docs.intersection_update(price_docs)\n",
    "\n",
    "    # Filtro per regione\n",
    "    if region_filter:\n",
    "        region_docs = set(data[data['country'].str.contains('|'.join(region_filter), case=False, na=False)].index)\n",
    "        matching_docs.intersection_update(region_docs)\n",
    "\n",
    "    # Filtro per carte di credito accettate\n",
    "    if credit_card_filter:\n",
    "        credit_docs = set(data[data['creditCards'].apply(lambda cards: any(card in cards for card in credit_card_filter))].index)\n",
    "        matching_docs.intersection_update(credit_docs)\n",
    "\n",
    "    # Filtro per servizi e strutture\n",
    "    if facilities_filter:\n",
    "        facilities_docs = set(data[data['facilitiesServices'].apply(lambda facilities: all(facility in facilities for facility in facilities_filter))].index)\n",
    "        matching_docs.intersection_update(facilities_docs)\n",
    "\n",
    "    # Restituzione dei ristoranti filtrati\n",
    "    filtered_restaurants = data.loc[list(matching_docs), ['restaurantName', 'address', 'city', 'priceRange', 'cuisineType', 'website']]\n",
    "    return filtered_restaurants\n",
    "\n",
    "\n",
    "# Interazione con l'utente per i nuovi filtri\n",
    "name_filter = input(\"Enter restaurant name: \")\n",
    "city_filter = input(\"Enter city: \")\n",
    "cuisine_filter = input(\"Enter cuisine type: \")\n",
    "\n",
    "# Filtro per fascia di prezzo\n",
    "price_range_filter = input(\"Enter price range (comma-separated, e.g., €€ or €€€): \").split(',') if input(\"Filter by price range? (yes/no): \").lower() == 'yes' else None\n",
    "\n",
    "# Filtro per regione\n",
    "region_filter = input(\"Enter Italian regions (comma-separated): \").split(',') if input(\"Filter by region? (yes/no): \").lower() == 'yes' else None\n",
    "\n",
    "# Filtro per carte di credito\n",
    "credit_card_filter = input(\"Enter accepted credit card types (comma-separated, e.g., Visa, MasterCard): \").split(',') if input(\"Filter by credit cards? (yes/no): \").lower() == 'yes' else None\n",
    "\n",
    "# Filtro per servizi\n",
    "facilities_filter = input(\"Enter required facilities/services (comma-separated, e.g., Wi-Fi, Parking): \").split(',') if input(\"Filter by facilities? (yes/no): \").lower() == 'yes' else None\n",
    "\n",
    "# Esegui la ricerca avanzata con tutti i filtri\n",
    "filtered_results = advanced_search_with_filters_enhanced(\n",
    "    df,\n",
    "    name_filter=name_filter,\n",
    "    city_filter=city_filter,\n",
    "    cuisine_filter=cuisine_filter,\n",
    "    price_range_filter=price_range_filter,\n",
    "    region_filter=region_filter,\n",
    "    credit_card_filter=credit_card_filter,\n",
    "    facilities_filter=facilities_filter\n",
    ")\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(filtered_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave a filter blank if you don't want to apply it.\n",
      "\n",
      "     restaurantName         address      city priceRange  \\\n",
      "356  O Me O Il Mare  Via Roma 45/47  Gragnano       €€€€   \n",
      "\n",
      "                              cuisineType                website  \n",
      "356  Italian Contemporary, Modern Cuisine  http://omeoilmare.com  \n"
     ]
    }
   ],
   "source": [
    "def advanced_search_with_filters_enhanced(data, name_filter='', city_filter='', cuisine_filter='', \n",
    "                                          price_range_filter=None, region_filter=None, \n",
    "                                          credit_card_filter=None, facilities_filter=None):\n",
    "    \"\"\"\n",
    "    Performs an advanced search with additional filters for price range, region, credit cards, and facilities.\n",
    "    \"\"\"\n",
    "    vocab, inverted_idx = build_vocabulary_and_inverted_indexes_case_insensitive(data)\n",
    "    matching_docs = set(data.index)\n",
    "\n",
    "    # Filtri base\n",
    "    if name_filter:\n",
    "        name_vocab, name_inv_idx = vocab['restaurantName'], inverted_idx['restaurantName']\n",
    "        name_results = conjunctive_query_case_insensitive(name_filter, name_vocab, name_inv_idx)\n",
    "        matching_docs.intersection_update(name_results)\n",
    "\n",
    "    if city_filter:\n",
    "        city_vocab, city_inv_idx = vocab['city'], inverted_idx['city']\n",
    "        city_results = conjunctive_query_case_insensitive(city_filter, city_vocab, city_inv_idx)\n",
    "        matching_docs.intersection_update(city_results)\n",
    "\n",
    "    if cuisine_filter:\n",
    "        cuisine_vocab, cuisine_inv_idx = vocab['cuisineType'], inverted_idx['cuisineType']\n",
    "        cuisine_results = conjunctive_query_case_insensitive(cuisine_filter, cuisine_vocab, cuisine_inv_idx)\n",
    "        matching_docs.intersection_update(cuisine_results)\n",
    "\n",
    "    # Filtro per fascia di prezzo\n",
    "    if price_range_filter:\n",
    "        price_docs = set(data[data['priceRange'].isin(price_range_filter)].index)\n",
    "        matching_docs.intersection_update(price_docs)\n",
    "\n",
    "    # Filtro per regione\n",
    "    if region_filter:\n",
    "        region_docs = set(data[data['country'].str.contains('|'.join(region_filter), case=False, na=False)].index)\n",
    "        matching_docs.intersection_update(region_docs)\n",
    "\n",
    "    # Filtro per carte di credito accettate\n",
    "    if credit_card_filter:\n",
    "        credit_docs = set(data[data['creditCards'].apply(lambda cards: any(card in cards for card in credit_card_filter))].index)\n",
    "        matching_docs.intersection_update(credit_docs)\n",
    "\n",
    "    # Filtro per servizi e strutture\n",
    "    if facilities_filter:\n",
    "        facilities_docs = set(data[data['facilitiesServices'].apply(lambda facilities: all(facility in facilities for facility in facilities_filter))].index)\n",
    "        matching_docs.intersection_update(facilities_docs)\n",
    "\n",
    "    # Restituzione dei ristoranti filtrati\n",
    "    filtered_restaurants = data.loc[list(matching_docs), ['restaurantName', 'address', 'city', 'priceRange', 'cuisineType', 'website']]\n",
    "    return filtered_restaurants\n",
    "\n",
    "\n",
    "# Interazione con l'utente per i nuovi filtri\n",
    "print(\"Leave a filter blank if you don't want to apply it.\\n\")\n",
    "\n",
    "name_filter = input(\"Enter restaurant name (or leave blank): \").strip()\n",
    "city_filter = input(\"Enter city (or leave blank): \").strip()\n",
    "cuisine_filter = input(\"Enter cuisine type (or leave blank): \").strip()\n",
    "\n",
    "# Filtro per fascia di prezzo\n",
    "price_range_filter = input(\"Enter price range (comma-separated, e.g., €€, €€€) or leave blank: \").split(',')\n",
    "price_range_filter = [p.strip() for p in price_range_filter if p.strip()]  # Rimuovi vuoti\n",
    "\n",
    "# Filtro per regione\n",
    "region_filter = input(\"Enter Italian regions (comma-separated) or leave blank: \").split(',')\n",
    "region_filter = [r.strip() for r in region_filter if r.strip()]  # Rimuovi vuoti\n",
    "\n",
    "# Filtro per carte di credito\n",
    "credit_card_filter = input(\"Enter accepted credit card types (comma-separated, e.g., Visa, MasterCard) or leave blank: \").split(',')\n",
    "credit_card_filter = [c.strip() for c in credit_card_filter if c.strip()]  # Rimuovi vuoti\n",
    "\n",
    "# Filtro per servizi\n",
    "facilities_filter = input(\"Enter required facilities/services (comma-separated, e.g., Wi-Fi, Parking) or leave blank: \").split(',')\n",
    "facilities_filter = [f.strip() for f in facilities_filter if f.strip()]  # Rimuovi vuoti\n",
    "\n",
    "# Esegui la ricerca avanzata con tutti i filtri\n",
    "filtered_results = advanced_search_with_filters_enhanced(\n",
    "    df,\n",
    "    name_filter=name_filter,\n",
    "    city_filter=city_filter,\n",
    "    cuisine_filter=cuisine_filter,\n",
    "    price_range_filter=price_range_filter if price_range_filter else None,\n",
    "    region_filter=region_filter if region_filter else None,\n",
    "    credit_card_filter=credit_card_filter if credit_card_filter else None,\n",
    "    facilities_filter=facilities_filter if facilities_filter else None\n",
    ")\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(filtered_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Question (AQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "RUUURRRRUU\n",
      "NO\n",
      "YES\n",
      "RRRRUUU\n"
     ]
    }
   ],
   "source": [
    "def collect_packages(num_tests, test_cases):\n",
    "    outcomes = []\n",
    "\n",
    "    for case_index in range(num_tests):\n",
    "        num_packages, package_coords = test_cases[case_index]\n",
    "\n",
    "        # Sort packages by coordinates (x, y) to ensure the smallest lexicographical path\n",
    "        package_coords.sort()\n",
    "\n",
    "        path_steps = []\n",
    "        reachable = True\n",
    "        curr_x, curr_y = 0, 0  # Start at (0, 0)\n",
    "\n",
    "        for target_x, target_y in package_coords:\n",
    "            # Check if the package is reachable from the current position\n",
    "            if target_x < curr_x or target_y < curr_y:\n",
    "                # If any package requires moving left or down, mark as unreachable\n",
    "                reachable = False\n",
    "                break\n",
    "\n",
    "            # Append necessary moves to reach the target package\n",
    "            path_steps.append('R' * (target_x - curr_x))  # Move right\n",
    "            path_steps.append('U' * (target_y - curr_y))  # Move up\n",
    "\n",
    "            # Update the current position to the target package's coordinates\n",
    "            curr_x, curr_y = target_x, target_y\n",
    "\n",
    "        if reachable:\n",
    "            # If all packages are reachable, append \"YES\" and the path\n",
    "            outcomes.append(\"YES\\n\" + ''.join(path_steps))\n",
    "        else:\n",
    "            # If any package is unreachable, append \"NO\"\n",
    "            outcomes.append(\"NO\")\n",
    "\n",
    "    return outcomes\n",
    "\n",
    "# Sample input data\n",
    "num_tests = 3\n",
    "test_cases = [\n",
    "    (5, [(1, 3), (1, 2), (3, 3), (5, 5), (4, 3)]),\n",
    "    (2, [(1, 0), (0, 1)]),\n",
    "    (1, [(4, 3)])\n",
    "]\n",
    "\n",
    "# Execute function and print results\n",
    "results = collect_packages(num_tests, test_cases)\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for the Algorithm\n",
    "\n",
    "Given a list of packages located on a grid, where each package is represented by coordinates \\((x_i, y_i)\\), and a robot starting at \\((0, 0)\\) that can only move right (`R`) and up (`U`):\n",
    "\n",
    "1. **Input**:\n",
    "   - \\( t \\): the number of test cases.\n",
    "   - For each test case:\n",
    "      - \\( n \\): the number of packages.\n",
    "      - A list of \\( n \\) packages with coordinates \\((x_i, y_i)\\).\n",
    "\n",
    "2. **Algorithm**:\n",
    "Start\n",
    "\n",
    "    Function collect_packages(t, test_cases):\n",
    "        Results = []   // List to store results for each test case\n",
    "        \n",
    "        For each test_case in test_cases:\n",
    "            (n, packages) = test_case     // Extract number of packages and their coordinates\n",
    "            Sort packages in ascending order by x, then by y    // Lexicographical sorting\n",
    "\n",
    "            current_x = 0   // Initial robot position (0, 0)\n",
    "            current_y = 0\n",
    "            path = \"\"    // String to build the path\n",
    "            possible = True\n",
    "\n",
    "            For each (x, y) in packages:\n",
    "                If x < current_x or y < current_y:\n",
    "                    possible = False   // If the package is unreachable (backward movement)\n",
    "                    Break the loop\n",
    "\n",
    "                // Add the necessary moves to reach the package (x, y)\n",
    "                path = path + \"R\" * (x - current_x)  // Add right movements\n",
    "                path = path + \"U\" * (y - current_y)  // Add upward movements\n",
    "\n",
    "                // Update the robot's position\n",
    "                current_x = x\n",
    "                current_y = y\n",
    "\n",
    "            If possible:\n",
    "                Append \"YES\" and path to Results\n",
    "            Else:\n",
    "                Append \"NO\" to Results\n",
    "\n",
    "        Return Results   // Return results for all test cases\n",
    "\n",
    "    // Input reading\n",
    "    t = input()   // Number of test cases\n",
    "    test_cases = []   // List to store test cases\n",
    "\n",
    "    For i = 1 to t:\n",
    "        n = input()   // Number of packages\n",
    "        packages = []   // List to store package coordinates\n",
    "\n",
    "        For j = 1 to n:\n",
    "            x, y = input()   // Package coordinates\n",
    "            packages.append((x, y))   // Add the package to the list\n",
    "\n",
    "        Append (n, packages) to test_cases   // Add the test case to the list\n",
    "\n",
    "    // Call the function and print the results\n",
    "    results = collect_packages(t, test_cases)\n",
    "    For each result in results:\n",
    "        Print result\n",
    "\n",
    "End\n",
    "\n",
    "\n",
    "### Proof of Correctness\n",
    "\n",
    "1. **Sorting Ensures Lexicographical Order**:\n",
    "   - Sorting the packages by $x$ and then $y$-coordinates ensures that we attempt to collect packages in the lexicographically smallest way.\n",
    "   - If there is an accessible path for all packages after sorting, this path will be the smallest lexicographical path because it minimizes right and upward movements in order.\n",
    "\n",
    "2. **Reachability Check**:\n",
    "   - By moving only right or up from each position, we guarantee that any unreachable package (one that would require moving left or down) will be detected and skipped. The algorithm returns \"NO\" in such cases.\n",
    "\n",
    "3. **Path Construction**:\n",
    "   - For each reachable package, the algorithm appends the correct number of `R` and `U` moves, ensuring that the robot reaches each package in the required order.\n",
    "\n",
    "4. **Conclusion**:\n",
    "   - The algorithm is correct because it verifies reachability and constructs the smallest lexicographical path if possible.\n",
    "\n",
    "### Time Complexity Analysis\n",
    "\n",
    "1. **Sorting the Packages**:\n",
    "   - Sorting the list of $n$ packages takes $O (\\frac{n}{log(n)})$ time.\n",
    "\n",
    "2. **Constructing the Path**:\n",
    "   - The path is constructed by iterating over each package, which takes $O(n)$ time. For each package, we calculate the difference in coordinates and append the required moves.\n",
    "\n",
    "3. **Overall Complexity**:\n",
    "   - The sorting step, $O (\\frac{n}{log(n)})$, is the most time-consuming operation in the algorithm, making the overall complexity: $O (\\frac{n}{log(n)})$\n",
    "\n",
    "### Verification with a Language Model's Analysis\n",
    "\n",
    "If you asked a language model to evaluate this code, it would likely arrive at the same time complexity, $O (\\frac{n}{log(n)})$ because sorting is the dominant step in this approach. If there were any discrepancies, they would likely stem from misunderstanding the nature of appending moves as an $O(n)$ operation. However, given that sorting $n$ packages is indeed $O (\\frac{n}{log(n)})$ and dominates the time complexity, our analysis is accurate.\n",
    "\n",
    "### Extending the Problem: Robot Can Move Left or Down\n",
    "\n",
    "With the new rule allowing movement in all directions (right, left, up, down), we consider a **greedy algorithm** where the robot collects the closest package from its current location.\n",
    "\n",
    "#### Is the Greedy Algorithm Optimal?\n",
    "\n",
    "1. **Greedy Approach**:\n",
    "   - At each step, the robot moves to the closest package, defined by the Euclidean distance or Manhattan distance from the current position.\n",
    "   - The robot continues selecting the nearest uncollected package until all packages are collected.\n",
    "\n",
    "2. **Counterexample to Greedy Optimality**:\n",
    "   - The greedy approach does not guarantee the minimum path length for the following reason:\n",
    "   - **Example**:\n",
    "     - Suppose there are packages at $(0, 1)$, $(1, 0)$, and $(2, 2)$, and the robot starts at $(0, 0)$.\n",
    "     - The greedy approach would choose either $(0, 1)$ or $(1, 0)$ first, then the remaining one, and finally $(2, 2)$.\n",
    "     - However, the optimal path would be to go directly to $(2, 2)$ first, then collect $(0, 1)$ and $(1, 0)$, which would result in a shorter total path.\n",
    "\n",
    "3. **Conclusion**:\n",
    "   - The greedy algorithm is **not optimal** for minimizing the total distance. While it may be intuitive and yield a quick solution, it does not guarantee the shortest path because the closest package does not necessarily contribute to the globally shortest route for all packages.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
