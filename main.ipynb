{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. Data Collection**\n",
    "### **1.1. Get the list of Michelin restaurants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "} # user agent is used to simulate that the http request comes from a real web browser, this prevent the server from blocking requests\n",
    "\n",
    "def guide_michelin(): # 2037\n",
    "        links = []\n",
    "        for i in range(1,101): #100\n",
    "            link = \"https://guide.michelin.com/en/it/restaurants/page/{}\".format(i)\n",
    "            try:\n",
    "                response = requests.get(link, headers=headers)\n",
    "            except Exception as e:\n",
    "                print(f\"{e} \\n {link}\")\n",
    "                continue\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                section = soup.find('div', class_=\"row restaurant__list-row js-restaurant__list_items\")\n",
    "                if section:  \n",
    "                    for a_tag in section.find_all('a', href=True):\n",
    "                        href = 'https://guide.michelin.com' + a_tag['href']\n",
    "                        if href not in links and \"/restaurant/\" in href: \n",
    "                            links.append(href)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve page {i}\")    \n",
    "        return links\n",
    "\n",
    "url_set = guide_michelin()\n",
    "print(len(url_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links.txt', 'w') as f:\n",
    "    for url in url_set:\n",
    "        f.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. Crawl Michelin restaurant pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML documents saved successfully.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('pages'):\n",
    "    os.makedirs('pages')\n",
    "\n",
    "with open('links.txt', 'r') as f:\n",
    "    urls = f.read().splitlines()\n",
    "\n",
    "# Create directories and save HTML documents\n",
    "for index, url in enumerate(urls):\n",
    "    page_number = index // 20 + 1\n",
    "    directory = os.path.join('pages', f'page_{page_number}')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            file_path = os.path.join(directory, f'document_{index}.html')\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "print(\"HTML documents saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_paths = [os.path.join('pages', dir) for dir in os.listdir('pages')]\n",
    "len(dir_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3. Parse downloaded pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract restaurant details from HTML content\n",
    "def extract_restaurant_details(content):\n",
    "    \n",
    "    # Extract the restaurant name\n",
    "    name = content.find('h1', class_='data-sheet__title').get_text(strip=True) if content.find('h1', class_='data-sheet__title') else \"\"\n",
    "    \n",
    "    # Extract the first row of basic information\n",
    "    firstRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[0].get_text(strip=True)\n",
    "    #firstRow = content.find(\"div\", class_=\"data-sheet__block--text\").get_text(strip=True)\n",
    "    firstRow_list = [info.strip() for info in firstRow.split(\",\")]\n",
    "\n",
    "    address = \" \".join(firstRow_list[:-3]) if len(firstRow_list) > 3 else \"\"\n",
    "    city = firstRow_list[-3] if len(firstRow_list) > 2 else \"\"\n",
    "    postalCode = firstRow_list[-2] if len(firstRow_list) > 1 else \"\"\n",
    "    country = firstRow_list[-1] if firstRow_list else \"\"\n",
    "\n",
    "    # Extract the second row of basic information\n",
    "    secondRow = content.find_all(\"div\", class_=\"data-sheet__block--text\")[1].get_text(strip=True)\n",
    "    #secondRow = content.find(\"div\", class_=\"data-sheet__block--text\").get_text(strip=True)\n",
    "    secondRow_list = [info.strip() for info in secondRow.split(\"·\")]\n",
    "\n",
    "    priceRange = secondRow_list[0] if secondRow_list else \"\"\n",
    "    cuisineType = secondRow_list[1] if len(secondRow_list) > 1 else \"\"\n",
    "\n",
    "    # Extract the description\n",
    "    description = content.find(\"div\", class_=\"data-sheet__description\").get_text(strip=True) if content.find(\"div\", class_=\"data-sheet__description\") else \"\"\n",
    "\n",
    "    # Extract facilities and services\n",
    "    facilitiesServices_div = content.find_all(\"div\", class_=\"col col-12 col-lg-6\")\n",
    "    # facilitiesServices_div = content.find(\"div\", class_=\"col col-12 col-lg-6\")\n",
    "    facilitiesServices = [li.get_text(strip=True) for li in facilitiesServices_div[0].find_all(\"li\")] if facilitiesServices_div else []\n",
    "    # facilitiesServices = [li.get_text(strip=True) for li in facilitiesServices_div.find(\"li\")] if facilitiesServices_div else []\n",
    "\n",
    "    # Extract credit card information\n",
    "    creditCards_div = content.find(\"div\", class_=\"restaurant-details__services--info\")\n",
    "    creditCards = [os.path.basename(img[\"data-src\"]).split(\"-\")[0] for img in creditCards_div.find_all(\"img\")] if creditCards_div else []\n",
    "\n",
    "    # Extract phone number\n",
    "    phoneNumber = content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}).get_text(strip=True) if content.find(\"span\", attrs={\"x-ms-format-detection\": \"none\"}) else \"\"\n",
    "\n",
    "    # Extract website\n",
    "    website_div = content.find(\"div\", class_=\"collapse__block-item link-item\")\n",
    "    website = website_div.find(\"a\", class_=\"link js-dtm-link\")[\"href\"] if website_div and website_div.find(\"a\", class_=\"link js-dtm-link\") else \"\"\n",
    "\n",
    "    # Return the extracted data as a dictionary\n",
    "    return {\n",
    "        \"restaurantName\": name,\n",
    "        \"address\": address,\n",
    "        \"city\": city,\n",
    "        \"postalCode\": postalCode,\n",
    "        \"country\": country,\n",
    "        \"priceRange\": priceRange,\n",
    "        \"cuisineType\": cuisineType,\n",
    "        \"description\": description,\n",
    "        \"facilitiesServices\": facilitiesServices,\n",
    "        \"creditCards\": creditCards,\n",
    "        \"phoneNumber\": phoneNumber,\n",
    "        \"website\": website\n",
    "    }\n",
    "\n",
    "# Collecting data from all HTML files\n",
    "#folder_paths = [d for d in os.listdir('pages') if os.path.isdir(d) and d.startswith(\"page_\")]\n",
    "dir_paths = [os.path.join('pages', dir) for dir in os.listdir('pages')]\n",
    "\n",
    "data = []\n",
    "for dir in dir_paths:\n",
    "    for html_file in os.listdir(dir):\n",
    "        if html_file.endswith(\".html\"):\n",
    "            with open(os.path.join(dir, html_file), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                restaurant_details = extract_restaurant_details(soup)\n",
    "                data.append(restaurant_details)\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns = [\"restaurantName\", \"address\", \"city\", \"postalCode\", \"country\", \"priceRange\", \"cuisineType\", \"description\", \"facilitiesServices\", \"creditCards\", \"phoneNumber\", \"website\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hydra</td>\n",
       "      <td>via Antonio Mazza 30</td>\n",
       "      <td>Salerno</td>\n",
       "      <td>84121</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Campanian, Contemporary</td>\n",
       "      <td>Situated in the picturesque historic centre of...</td>\n",
       "      <td>[Air conditioning, Restaurant offering vegetar...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 089 995 8437</td>\n",
       "      <td>http://www.ristorantehydra.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gimmi Restaurant</td>\n",
       "      <td>via San Pietro in Lama 23</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>73100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Contemporary</td>\n",
       "      <td>Despite its location in a Dominican monastery ...</td>\n",
       "      <td>[Air conditioning, Terrace, Wheelchair access]</td>\n",
       "      <td>[amex, maestrocard, mastercard, visa]</td>\n",
       "      <td>+39 0832 700920</td>\n",
       "      <td>https://www.chiostrodeidomenicani.it/ristorante/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Felix Lo Basso home &amp; restaurant</td>\n",
       "      <td>via Carlo Goldoni 36</td>\n",
       "      <td>Milan</td>\n",
       "      <td>20129</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Italian Contemporary, Creative</td>\n",
       "      <td>Brilliant chef Felix Lo Basso’s menu is inspir...</td>\n",
       "      <td>[Air conditioning, Counter dining, Wheelchair ...</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 02 4540 9759</td>\n",
       "      <td>https://www.felixlobassorestaurant.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Acciuga</td>\n",
       "      <td>via Settevalli 217</td>\n",
       "      <td>Perugia</td>\n",
       "      <td>06128</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Contemporary, International</td>\n",
       "      <td>You would never guess that there was a gourmet...</td>\n",
       "      <td>[Air conditioning, Interesting wine list, Terr...</td>\n",
       "      <td>[amex, unionpay, dinersclub, discover, jcb, ma...</td>\n",
       "      <td>+39 339 263 2591</td>\n",
       "      <td>https://www.lacciuga.net/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antiche Sere</td>\n",
       "      <td>via Cenischia 9</td>\n",
       "      <td>Turin</td>\n",
       "      <td>10139</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€</td>\n",
       "      <td>Piedmontese, Classic Cuisine</td>\n",
       "      <td>This renowned osteria situated in a district o...</td>\n",
       "      <td>[Air conditioning, Terrace]</td>\n",
       "      <td>[dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 011 385 4347</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Vintage 1997</td>\n",
       "      <td>piazza Solferino 16/h</td>\n",
       "      <td>Turin</td>\n",
       "      <td>10121</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Italian, Classic Cuisine</td>\n",
       "      <td>The several tasting menus at this restaurant i...</td>\n",
       "      <td>[Air conditioning, Interesting wine list, Rest...</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 011 535948</td>\n",
       "      <td>https://www.vintage1997.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Locanda Margon</td>\n",
       "      <td>via Margone 15</td>\n",
       "      <td>Ravina</td>\n",
       "      <td>38123</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative, Contemporary</td>\n",
       "      <td>This restaurant with views of Trento and the A...</td>\n",
       "      <td>[Air conditioning, Car park, Garden or park, G...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 0461 349401</td>\n",
       "      <td>https://www.locandamargon.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Bon Wei</td>\n",
       "      <td>via Castelvetro 16/18</td>\n",
       "      <td>Milan</td>\n",
       "      <td>20154</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>China on a plate! This attractive restaurant w...</td>\n",
       "      <td>[Air conditioning, Wheelchair access]</td>\n",
       "      <td>[amex, mastercard, visa]</td>\n",
       "      <td>+39 02 341308</td>\n",
       "      <td>https://www.bon-wei.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Le Lampare al Fortino</td>\n",
       "      <td>via Tiepolo molo Sant'Antonio</td>\n",
       "      <td>Trani</td>\n",
       "      <td>76125</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Mediterranean Cuisine, Modern Cuisine</td>\n",
       "      <td>Built over a medieval church, this old fort th...</td>\n",
       "      <td>[Air conditioning, Great view, Interesting win...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 0883 480308</td>\n",
       "      <td>https://www.lelamparealfortino.it/it/home/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Veneziano</td>\n",
       "      <td>Contrada Arena SS 120 km 187</td>\n",
       "      <td>Randazzo</td>\n",
       "      <td>95036</td>\n",
       "      <td>Italy</td>\n",
       "      <td>€€</td>\n",
       "      <td>Sicilian, Traditional Cuisine</td>\n",
       "      <td>Situated just outside Randazzo, one of the vil...</td>\n",
       "      <td>[Air conditioning, Car park, Garden or park, T...</td>\n",
       "      <td>[amex, dinersclub, mastercard, visa]</td>\n",
       "      <td>+39 095 799 1353</td>\n",
       "      <td>https://www.ristoranteveneziano.it/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1983 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        restaurantName                        address  \\\n",
       "0                                Hydra           via Antonio Mazza 30   \n",
       "1                     Gimmi Restaurant      via San Pietro in Lama 23   \n",
       "2     Felix Lo Basso home & restaurant           via Carlo Goldoni 36   \n",
       "3                            L'Acciuga             via Settevalli 217   \n",
       "4                         Antiche Sere                via Cenischia 9   \n",
       "...                                ...                            ...   \n",
       "1978                      Vintage 1997          piazza Solferino 16/h   \n",
       "1979                    Locanda Margon                 via Margone 15   \n",
       "1980                           Bon Wei          via Castelvetro 16/18   \n",
       "1981             Le Lampare al Fortino  via Tiepolo molo Sant'Antonio   \n",
       "1982                         Veneziano   Contrada Arena SS 120 km 187   \n",
       "\n",
       "          city postalCode country priceRange  \\\n",
       "0      Salerno      84121   Italy         €€   \n",
       "1        Lecce      73100   Italy        €€€   \n",
       "2        Milan      20129   Italy       €€€€   \n",
       "3      Perugia      06128   Italy        €€€   \n",
       "4        Turin      10139   Italy          €   \n",
       "...        ...        ...     ...        ...   \n",
       "1978     Turin      10121   Italy        €€€   \n",
       "1979    Ravina      38123   Italy       €€€€   \n",
       "1980     Milan      20154   Italy         €€   \n",
       "1981     Trani      76125   Italy        €€€   \n",
       "1982  Randazzo      95036   Italy         €€   \n",
       "\n",
       "                                cuisineType  \\\n",
       "0                   Campanian, Contemporary   \n",
       "1                              Contemporary   \n",
       "2            Italian Contemporary, Creative   \n",
       "3               Contemporary, International   \n",
       "4              Piedmontese, Classic Cuisine   \n",
       "...                                     ...   \n",
       "1978               Italian, Classic Cuisine   \n",
       "1979                 Creative, Contemporary   \n",
       "1980                         Chinese, Asian   \n",
       "1981  Mediterranean Cuisine, Modern Cuisine   \n",
       "1982          Sicilian, Traditional Cuisine   \n",
       "\n",
       "                                            description  \\\n",
       "0     Situated in the picturesque historic centre of...   \n",
       "1     Despite its location in a Dominican monastery ...   \n",
       "2     Brilliant chef Felix Lo Basso’s menu is inspir...   \n",
       "3     You would never guess that there was a gourmet...   \n",
       "4     This renowned osteria situated in a district o...   \n",
       "...                                                 ...   \n",
       "1978  The several tasting menus at this restaurant i...   \n",
       "1979  This restaurant with views of Trento and the A...   \n",
       "1980  China on a plate! This attractive restaurant w...   \n",
       "1981  Built over a medieval church, this old fort th...   \n",
       "1982  Situated just outside Randazzo, one of the vil...   \n",
       "\n",
       "                                     facilitiesServices  \\\n",
       "0     [Air conditioning, Restaurant offering vegetar...   \n",
       "1        [Air conditioning, Terrace, Wheelchair access]   \n",
       "2     [Air conditioning, Counter dining, Wheelchair ...   \n",
       "3     [Air conditioning, Interesting wine list, Terr...   \n",
       "4                           [Air conditioning, Terrace]   \n",
       "...                                                 ...   \n",
       "1978  [Air conditioning, Interesting wine list, Rest...   \n",
       "1979  [Air conditioning, Car park, Garden or park, G...   \n",
       "1980              [Air conditioning, Wheelchair access]   \n",
       "1981  [Air conditioning, Great view, Interesting win...   \n",
       "1982  [Air conditioning, Car park, Garden or park, T...   \n",
       "\n",
       "                                            creditCards       phoneNumber  \\\n",
       "0                  [amex, dinersclub, mastercard, visa]  +39 089 995 8437   \n",
       "1                 [amex, maestrocard, mastercard, visa]   +39 0832 700920   \n",
       "2                              [amex, mastercard, visa]  +39 02 4540 9759   \n",
       "3     [amex, unionpay, dinersclub, discover, jcb, ma...  +39 339 263 2591   \n",
       "4                        [dinersclub, mastercard, visa]  +39 011 385 4347   \n",
       "...                                                 ...               ...   \n",
       "1978                           [amex, mastercard, visa]    +39 011 535948   \n",
       "1979               [amex, dinersclub, mastercard, visa]   +39 0461 349401   \n",
       "1980                           [amex, mastercard, visa]     +39 02 341308   \n",
       "1981               [amex, dinersclub, mastercard, visa]   +39 0883 480308   \n",
       "1982               [amex, dinersclub, mastercard, visa]  +39 095 799 1353   \n",
       "\n",
       "                                               website  \n",
       "0                       http://www.ristorantehydra.com  \n",
       "1     https://www.chiostrodeidomenicani.it/ristorante/  \n",
       "2               https://www.felixlobassorestaurant.it/  \n",
       "3                            https://www.lacciuga.net/  \n",
       "4                                                       \n",
       "...                                                ...  \n",
       "1978                      https://www.vintage1997.com/  \n",
       "1979                     https://www.locandamargon.it/  \n",
       "1980                           https://www.bon-wei.it/  \n",
       "1981        https://www.lelamparealfortino.it/it/home/  \n",
       "1982               https://www.ristoranteveneziano.it/  \n",
       "\n",
       "[1983 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (4.67.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize and remove stopwords, then apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply to the description field\n",
    "df['processed_description'] = df['description'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conjunctive Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create the Index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = {}\n",
    "inverted_index = defaultdict(list)\n",
    "term_id_counter = 0\n",
    "\n",
    "for doc_id, description in enumerate(df['processed_description']):\n",
    "    for word in description.split():\n",
    "        # Map each unique word to a term_id\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = term_id_counter\n",
    "            term_id_counter += 1\n",
    "        term_id = vocabulary[word]\n",
    "        inverted_index[term_id].append(doc_id)\n",
    "\n",
    "# Save the vocabulary to a CSV file\n",
    "pd.DataFrame(list(vocabulary.items()), columns=['term', 'term_id']).to_csv('vocabulary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('inverted_index.json', 'w') as f:\n",
    "    json.dump(inverted_index, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    query = query.lower()\n",
    "    query = query.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = [stemmer.stem(word) for word in query.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def conjunctive_query(query):\n",
    "    query_terms = preprocess_query(query)\n",
    "    term_ids = [vocabulary.get(term) for term in query_terms if term in vocabulary]\n",
    "\n",
    "    if not term_ids:\n",
    "        return pd.DataFrame(columns=[\"restaurantName\", \"address\", \"description\", \"website\"])\n",
    "\n",
    "    # Start with the document list for the first term, then intersect with others\n",
    "    matching_docs = set(inverted_index[term_ids[0]])\n",
    "    for term_id in term_ids[1:]:\n",
    "        matching_docs &= set(inverted_index[term_id])\n",
    "\n",
    "    results = df.loc[list(matching_docs), [\"restaurantName\", \"address\", \"description\", \"website\"]]\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_index = defaultdict(list)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Loop over each term (feature) in the TF-IDF matrix\n",
    "for term_id, term in enumerate(feature_names):\n",
    "    # Get non-zero document indices and the corresponding scores for this term\n",
    "    doc_indices = tfidf_matrix[:, term_id].nonzero()[0]\n",
    "    scores = tfidf_matrix[:, term_id].data\n",
    "    \n",
    "    # Append each document ID and score to the tfidf_index dictionary \n",
    "    for doc_id, score in zip(doc_indices, scores):\n",
    "        tfidf_index[term].append((doc_id, score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ranked Search Engine with TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def ranked_query(query, top_k=5):\n",
    "    query_vec = tfidf_vectorizer.transform([preprocess_text(query)])\n",
    "    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    top_doc_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = df.loc[top_doc_indices, ['restaurantName', 'address', 'description', 'website']]\n",
    "    results['similarity_score'] = cosine_similarities[top_doc_indices]\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      restaurantName                         address  \\\n",
      "111  Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
      "\n",
      "                                           description website  \n",
      "111  This pleasant, warmly decorated restaurant is ...          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Osteria Taviani</td>\n",
       "      <td>piazza Vittorio Emanuele II 28</td>\n",
       "      <td>This pleasant, warmly decorated restaurant is ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      restaurantName                         address  \\\n",
       "111  Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
       "\n",
       "                                           description website  \n",
       "111  This pleasant, warmly decorated restaurant is ...          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       restaurantName                         address  \\\n",
      "111   Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
      "238          Menzaghi             via San Giovanni 74   \n",
      "1497       SaleGrosso              viale II Giugno 15   \n",
      "1673   Marsupino 1901               via Roma Serra 20   \n",
      "1818   Lio Pellegrini               via San Tomaso 47   \n",
      "\n",
      "                                            description  \\\n",
      "111   This pleasant, warmly decorated restaurant is ...   \n",
      "238   Once you’ve found the car park, make your way ...   \n",
      "1497  One of the town’s authentic favourites, this f...   \n",
      "1673  The Marsupino family has been running this tra...   \n",
      "1818  Despite its location in the town centre, the a...   \n",
      "\n",
      "                                 website  similarity_score  \n",
      "111                                               0.302989  \n",
      "238   https://www.ristorantemenzaghi.it/          0.221025  \n",
      "1497  http://www.ristorantesalegrosso.it          0.203840  \n",
      "1673  https://www.trattoriamarsupino.it/          0.174293  \n",
      "1818  https://www.liopellegrini.it/site/          0.172042  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Osteria Taviani</td>\n",
       "      <td>piazza Vittorio Emanuele II 28</td>\n",
       "      <td>This pleasant, warmly decorated restaurant is ...</td>\n",
       "      <td></td>\n",
       "      <td>0.302989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Menzaghi</td>\n",
       "      <td>via San Giovanni 74</td>\n",
       "      <td>Once you’ve found the car park, make your way ...</td>\n",
       "      <td>https://www.ristorantemenzaghi.it/</td>\n",
       "      <td>0.221025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>SaleGrosso</td>\n",
       "      <td>viale II Giugno 15</td>\n",
       "      <td>One of the town’s authentic favourites, this f...</td>\n",
       "      <td>http://www.ristorantesalegrosso.it</td>\n",
       "      <td>0.203840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Marsupino 1901</td>\n",
       "      <td>via Roma Serra 20</td>\n",
       "      <td>The Marsupino family has been running this tra...</td>\n",
       "      <td>https://www.trattoriamarsupino.it/</td>\n",
       "      <td>0.174293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Lio Pellegrini</td>\n",
       "      <td>via San Tomaso 47</td>\n",
       "      <td>Despite its location in the town centre, the a...</td>\n",
       "      <td>https://www.liopellegrini.it/site/</td>\n",
       "      <td>0.172042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       restaurantName                         address  \\\n",
       "111   Osteria Taviani  piazza Vittorio Emanuele II 28   \n",
       "238          Menzaghi             via San Giovanni 74   \n",
       "1497       SaleGrosso              viale II Giugno 15   \n",
       "1673   Marsupino 1901               via Roma Serra 20   \n",
       "1818   Lio Pellegrini               via San Tomaso 47   \n",
       "\n",
       "                                            description  \\\n",
       "111   This pleasant, warmly decorated restaurant is ...   \n",
       "238   Once you’ve found the car park, make your way ...   \n",
       "1497  One of the town’s authentic favourites, this f...   \n",
       "1673  The Marsupino family has been running this tra...   \n",
       "1818  Despite its location in the town centre, the a...   \n",
       "\n",
       "                                 website  similarity_score  \n",
       "111                                               0.302989  \n",
       "238   https://www.ristorantemenzaghi.it/          0.221025  \n",
       "1497  http://www.ristorantesalegrosso.it          0.203840  \n",
       "1673  https://www.trattoriamarsupino.it/          0.174293  \n",
       "1818  https://www.liopellegrini.it/site/          0.172042  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the conjunctive query\n",
    "query = \"This pleasant, warmly decorated restaurant is ...\"\n",
    "conjunctive_results = conjunctive_query(query)\n",
    "print(conjunctive_results)\n",
    "display(conjunctive_results)\n",
    "# Test the ranked query\n",
    "ranked_results = ranked_query(query, top_k=5)\n",
    "print(ranked_results)\n",
    "display(ranked_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a New Score!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(query, tfidf_vectorizer, tfidf_matrix):\n",
    "    # Convert the query into a TF-IDF vector\n",
    "    query_tfidf = tfidf_vectorizer.transform([query])\n",
    "    \n",
    "     # Compute cosine similarity between the query vector and all document vectors\n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    #Return similarity scores for all documents\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for custom ranking. \n",
    "def custom_scoring(query, df, tfidf_vectorizer, tfidf_matrix, top_k=5, cuisine_preferences=None, service_preferences=None, price_preferences=None):\n",
    "    # Define differents weights for description, cuisine, facilities and price.\n",
    "    DESCRIPTION_WEIGHT = 0.5\n",
    "    CUISINE_WEIGHT = 0.2\n",
    "    FACILITIES_WEIGHT = 0.2\n",
    "    PRICE_WEIGHT = 0.3\n",
    "\n",
    "    # Calculate cosine similarities between the query and all descriptions\n",
    "    cosine_similarities = calculate_cosine_similarity(query, tfidf_vectorizer, tfidf_matrix)\n",
    "    top_k_restaurants = []\n",
    "\n",
    "    # Iterate over all documents and calculate the custom score for each\n",
    "    for doc_id, cosine_score in enumerate(cosine_similarities):\n",
    "        # Score based on description similarity\n",
    "        description_score = cosine_score * DESCRIPTION_WEIGHT\n",
    "\n",
    "        # Score for matching \"cuisineType\"\n",
    "        cuisine_score = 0\n",
    "        if 'cuisineType' in df.columns and cuisine_preferences:\n",
    "            for pref in cuisine_preferences:\n",
    "                if pref.lower() in df.loc[doc_id, 'cuisineType'].lower():\n",
    "                    cuisine_score += CUISINE_WEIGHT\n",
    "\n",
    "        # Score for matching \"facilitiesServices\"\n",
    "        facilities_score = 0\n",
    "        if 'facilitiesServices' in df.columns and service_preferences:\n",
    "            facilities = df.loc[doc_id, 'facilitiesServices']\n",
    "            if isinstance(facilities, list):\n",
    "                for service in service_preferences:\n",
    "                    if any(service.lower() == facility.lower() for facility in facilities):\n",
    "                        facilities_score += FACILITIES_WEIGHT\n",
    "\n",
    "        # Score for matching \"priceRange\"\n",
    "        price_score = 0\n",
    "        if 'priceRange' in df.columns and price_preferences:\n",
    "            price_range = df.loc[doc_id, 'priceRange']\n",
    "            for price in price_preferences:\n",
    "                if price in price_range:\n",
    "                    price_score += PRICE_WEIGHT\n",
    "\n",
    "        # Calculate the final custom score\n",
    "        final_score = description_score + cuisine_score + facilities_score + price_score\n",
    "\n",
    "        # Add to the heap to maintain top-k results\n",
    "        if len(top_k_restaurants) < top_k:\n",
    "            heapq.heappush(top_k_restaurants, (final_score, doc_id))\n",
    "        else:\n",
    "            heapq.heappushpop(top_k_restaurants, (final_score, doc_id))\n",
    "\n",
    "    # Sort the top-k results by score in descending order\n",
    "    top_k_restaurants = sorted(top_k_restaurants, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Prepare the final output\n",
    "    results = []\n",
    "    for score, doc_id in top_k_restaurants:\n",
    "        results.append({\n",
    "            \"restaurantName\": df.loc[doc_id, \"restaurantName\"],\n",
    "            \"address\": df.loc[doc_id, \"address\"],\n",
    "            \"description\": df.loc[doc_id, \"description\"],\n",
    "            \"website\": df.loc[doc_id, \"website\"],\n",
    "            \"custom_score\": round(score, 3)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "      <th>custom_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'Osteria di Santa Marina</td>\n",
       "      <td>campo Santa Marina sestiere di Castello 5911</td>\n",
       "      <td>This classy inn is managed by young profession...</td>\n",
       "      <td>https://osteriadisantamarina.com/</td>\n",
       "      <td>1.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Lampare al Fortino</td>\n",
       "      <td>via Tiepolo molo Sant'Antonio</td>\n",
       "      <td>Built over a medieval church, this old fort th...</td>\n",
       "      <td>https://www.lelamparealfortino.it/it/home/</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Essenza Bistrot</td>\n",
       "      <td>via delle Terme 8/A</td>\n",
       "      <td>A welcoming and original bistro-restaurant in ...</td>\n",
       "      <td>https://www.essenzabistrot.it</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jamantè</td>\n",
       "      <td>via San Vito 97</td>\n",
       "      <td>Located not far from the historic centre and t...</td>\n",
       "      <td>https://www.jamanteristorante.com</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Livello 1</td>\n",
       "      <td>via Duccio di Buoninsegna 25</td>\n",
       "      <td>Situated in the suburbs off the main tourist t...</td>\n",
       "      <td>http://www.ristorantelivello1.it</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              restaurantName                                       address  \\\n",
       "0  L'Osteria di Santa Marina  campo Santa Marina sestiere di Castello 5911   \n",
       "1      Le Lampare al Fortino                 via Tiepolo molo Sant'Antonio   \n",
       "2            Essenza Bistrot                           via delle Terme 8/A   \n",
       "3                    Jamantè                               via San Vito 97   \n",
       "4                  Livello 1                  via Duccio di Buoninsegna 25   \n",
       "\n",
       "                                         description  \\\n",
       "0  This classy inn is managed by young profession...   \n",
       "1  Built over a medieval church, this old fort th...   \n",
       "2  A welcoming and original bistro-restaurant in ...   \n",
       "3  Located not far from the historic centre and t...   \n",
       "4  Situated in the suburbs off the main tourist t...   \n",
       "\n",
       "                                      website  custom_score  \n",
       "0           https://osteriadisantamarina.com/         1.011  \n",
       "1  https://www.lelamparealfortino.it/it/home/         0.981  \n",
       "2               https://www.essenzabistrot.it         0.976  \n",
       "3           https://www.jamanteristorante.com         0.967  \n",
       "4            http://www.ristorantelivello1.it         0.965  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define the query and the user's preferences\n",
    "query = \"seafood\"\n",
    "cuisine_preferences = [\"Modern Cuisine\"]\n",
    "service_preferences = [\"Terrace\", \"Air conditioning\"]   \n",
    "price_preferences = [\"€€€\"]\n",
    "top_k = 5\n",
    "\n",
    "# Call the custom scoring function and display the results\n",
    "results_df = custom_scoring(query, df, tfidf_vectorizer, tfidf_matrix, top_k, cuisine_preferences, service_preferences,  price_preferences)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Bonus \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [restaurantName, address, cuisineType, priceRange, website]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to preprocess text for tokenization and normalization\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses the text by converting to lowercase and splitting into tokens.\"\"\"\n",
    "    return text.lower().split()\n",
    "\n",
    "# Function to build vocabularies and inverted indexes\n",
    "def build_vocabulary_and_inverted_indexes(df):\n",
    "    \"\"\"\n",
    "    Builds vocabularies and inverted indexes for restaurantName, city, and cuisineType fields.\n",
    "    \"\"\"\n",
    "    vocab = {\n",
    "        'restaurantName': {},\n",
    "        'city': {},\n",
    "        'cuisineType': {}\n",
    "    }\n",
    "    \n",
    "    inverted_index = {\n",
    "        'restaurantName': defaultdict(set),\n",
    "        'city': defaultdict(set),\n",
    "        'cuisineType': defaultdict(set)\n",
    "    }\n",
    "    \n",
    "    term_counter = {\n",
    "        'restaurantName': 0,\n",
    "        'city': 0,\n",
    "        'cuisineType': 0\n",
    "    }\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for record_id, row in df.iterrows():\n",
    "        for field in ['restaurantName', 'city', 'cuisineType']:\n",
    "            tokens = preprocess_text(row[field]) if pd.notnull(row[field]) else []\n",
    "\n",
    "            for token in tokens:\n",
    "                # Add token to vocabulary and assign term ID if not already present\n",
    "                if token not in vocab[field]:\n",
    "                    vocab[field][token] = term_counter[field]\n",
    "                    term_counter[field] += 1\n",
    "\n",
    "                # Add record ID to the inverted index for this term\n",
    "                term_id = vocab[field][token]\n",
    "                inverted_index[field][term_id].add(record_id)\n",
    "\n",
    "    return vocab, inverted_index\n",
    "\n",
    "# Function for conjunctive query\n",
    "def conjunctive_query(query, vocab, inverted_index):\n",
    "    \"\"\"\n",
    "    Performs a conjunctive query to find matching documents based on the query terms.\n",
    "    \"\"\"\n",
    "    query_tokens = preprocess_text(query)\n",
    "    query_term_ids = [vocab.get(token) for token in query_tokens if token in vocab]\n",
    "\n",
    "    if not query_term_ids:\n",
    "        return set()\n",
    "\n",
    "    doc_sets = [inverted_index[term_id] for term_id in query_term_ids if term_id in inverted_index]\n",
    "\n",
    "    return set.intersection(*doc_sets) if doc_sets else set()\n",
    "\n",
    "# Advanced search with filters\n",
    "def advanced_field_query(data, name_filter='', city_filter='', cuisine_filter=''):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame using the specified filters for restaurantName, city, and cuisineType.\n",
    "    \"\"\"\n",
    "    vocab, inverted_idx = build_vocabulary_and_inverted_indexes(data)\n",
    "    matching_docs = set(data.index)\n",
    "\n",
    "    if name_filter:\n",
    "        name_vocab, name_inv_idx = vocab['restaurantName'], inverted_idx['restaurantName']\n",
    "        name_results = conjunctive_query(name_filter, name_vocab, name_inv_idx)\n",
    "        matching_docs.intersection_update(name_results)\n",
    "\n",
    "    if city_filter:\n",
    "        city_vocab, city_inv_idx = vocab['city'], inverted_idx['city']\n",
    "        city_results = conjunctive_query(city_filter, city_vocab, city_inv_idx)\n",
    "        matching_docs.intersection_update(city_results)\n",
    "\n",
    "    if cuisine_filter:\n",
    "        cuisine_vocab, cuisine_inv_idx = vocab['cuisineType'], inverted_idx['cuisineType']\n",
    "        cuisine_results = conjunctive_query(cuisine_filter, cuisine_vocab, cuisine_inv_idx)\n",
    "        matching_docs.intersection_update(cuisine_results)\n",
    "\n",
    "    return data.loc[list(matching_docs), :]\n",
    "\n",
    "# Function to apply additional filters\n",
    "def filter_results(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies additional filters like price range, region, facilities, and credit cards to the results.\n",
    "    \"\"\"\n",
    "    # Collect user input for advanced filters\n",
    "    restaurant_name_query = input(\"Enter restaurant name to search: \")\n",
    "    city_query = input(\"Enter city to search: \")\n",
    "    cuisine_type_query = input(\"Enter cuisine type to search: \")\n",
    "    \n",
    "    results = advanced_field_query(data, restaurant_name_query, city_query, cuisine_type_query)\n",
    "    \n",
    "    price_range_filter = input(\"Enter price ranges to filter, separated by spaces (e.g., €, €€, €€€, €€€€): \").split()\n",
    "    region_filter = input(\"Enter regions to filter, separated by spaces: \").split()\n",
    "    region_filter = [region.title() for region in region_filter]\n",
    "    facilities_filter = input(\"Enter facilities/services to filter, separated by spaces: \").split()\n",
    "    facilities_filter = [facility.title() for facility in facilities_filter]\n",
    "    credit_cards_filter = input(\"Enter accepted credit cards to filter, separated by spaces: \").split()\n",
    "    credit_cards_filter = [card.title() for card in credit_cards_filter]\n",
    "\n",
    "    # Apply filters on the results\n",
    "    if not results.empty:\n",
    "        if price_range_filter:\n",
    "            results = results[results['priceRange'].isin(price_range_filter)]\n",
    "        if region_filter:\n",
    "            results = results[results['city'].isin(region_filter)]\n",
    "        if facilities_filter:\n",
    "            results = results[results['facilitiesServices'].apply(\n",
    "                lambda x: all(facility in x for facility in facilities_filter) if isinstance(x, list) else False)]\n",
    "        if credit_cards_filter:\n",
    "            results = results[results['creditCards'].apply(\n",
    "                lambda x: any(card in x for card in credit_cards_filter) if isinstance(x, list) else False)]\n",
    "\n",
    "    # Display selected columns\n",
    "    display_columns = results[['restaurantName', 'address', 'cuisineType', 'priceRange', 'website']]\n",
    "    return display_columns\n",
    "\n",
    "# Execute the filtering process\n",
    "filtered_results = filter_results(df)\n",
    "\n",
    "# Display the filtered results\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def create_vocabularies_and_indexes(data):\n",
    "    vocabularies = {\n",
    "        'restaurantName': {},\n",
    "        'city': {},\n",
    "        'cuisineType': {}\n",
    "    }\n",
    "    inverted_indexes = {\n",
    "        'restaurantName': defaultdict(set),\n",
    "        'city': defaultdict(set),\n",
    "        'cuisineType': defaultdict(set)\n",
    "    }\n",
    "    term_ids = {\n",
    "        'restaurantName': 0,\n",
    "        'city': 0,\n",
    "        'cuisineType': 0\n",
    "    }\n",
    "\n",
    "    # Loop through each restaurant document\n",
    "    for doc_id, row in data.iterrows():\n",
    "        for field in ['restaurantName', 'city', 'cuisineType']:\n",
    "            tokens = preprocess_text(row[field])\n",
    "\n",
    "            for token in tokens:\n",
    "                # Assign a new term ID if token not in vocabulary for the field\n",
    "                if token not in vocabularies[field]:\n",
    "                    vocabularies[field][token] = term_ids[field]\n",
    "                    term_ids[field] += 1\n",
    "\n",
    "                # Add the doc_id to the inverted index for this token in the field\n",
    "                term_id = vocabularies[field][token]\n",
    "                inverted_indexes[field][term_id].add(doc_id)\n",
    "\n",
    "    return vocabularies, inverted_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjunctive_query_ad(query, vocabulary, inverted_index):\n",
    "    # Preprocess the query text and convert it to term IDs using the vocabulary\n",
    "    query_tokens = preprocess_text(query)\n",
    "    query_term_ids = [vocabulary.get(token) for token in query_tokens if token in vocabulary]\n",
    "\n",
    "    # If no terms from the query are found in the vocabulary, return an empty set\n",
    "    if not query_term_ids:\n",
    "        return set()\n",
    "\n",
    "    # Find documents containing all term IDs from the query\n",
    "    doc_lists = [set(inverted_index[tid]) for tid in query_term_ids if tid in inverted_index]\n",
    "\n",
    "    # Intersect document lists to get documents that contain all query terms\n",
    "    if doc_lists:\n",
    "        matching_docs = set.intersection(*doc_lists)\n",
    "    else:\n",
    "        matching_docs = set()\n",
    "\n",
    "    # Return the set of matching document indices\n",
    "    return matching_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_field_query(data, restaurant_name_query='', city_query='', cuisine_type_query=''):\n",
    "    # Create vocabularies and inverted indexes for each field\n",
    "    vocabularies, inverted_indexes = create_vocabularies_and_indexes(data)\n",
    "    \n",
    "    # Initialize results as a set of all document indices\n",
    "    results = set(data.index)\n",
    "\n",
    "    # Perform search on `restaurantName` if `restaurant_name_query` is not empty\n",
    "    if restaurant_name_query:\n",
    "        vocabR, invIndexR = vocabularies['restaurantName'], inverted_indexes['restaurantName']\n",
    "        resultsR = conjunctive_query_ad(restaurant_name_query, vocabR, invIndexR)\n",
    "        results.intersection_update(resultsR)\n",
    "\n",
    "    # Perform search on `city` if `city_query` is not empty\n",
    "    if city_query:\n",
    "        vocabC, invIndexC = vocabularies['city'], inverted_indexes['city']\n",
    "        resultsC = conjunctive_query_ad(city_query, vocabC, invIndexC)\n",
    "        results.intersection_update(resultsC)\n",
    "\n",
    "    # Perform search on `cuisineType` if `cuisine_type_query` is not empty\n",
    "    if cuisine_type_query:\n",
    "        vocabCT, invIndexCT = vocabularies['cuisineType'], inverted_indexes['cuisineType']\n",
    "        resultsCT = conjunctive_query_ad(cuisine_type_query, vocabCT, invIndexCT)\n",
    "        results.intersection_update(resultsCT)\n",
    "\n",
    "    # Display the filtered data with the relevant columns\n",
    "    filtered_data = data.loc[list(results), ['restaurantName', 'address', 'cuisineType', 'priceRange', 'website']]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m cuisine_type_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter cuisine type to search: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the query\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43madvanced_field_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestaurant_name_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuisine_type_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m results\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36madvanced_field_query\u001b[0;34m(data, restaurant_name_query, city_query, cuisine_type_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvanced_field_query\u001b[39m(data, restaurant_name_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, city_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, cuisine_type_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Create vocabularies and inverted indexes for each field\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     vocabularies, inverted_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_vocabularies_and_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Initialize results as a set of all document indices\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex)\n",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m, in \u001b[0;36mcreate_vocabularies_and_indexes\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m term_ids \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestaurantName\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisineType\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Loop through each restaurant document\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_id, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m():\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestaurantName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisineType\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     22\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m preprocess_text(row[field])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "# Prompt user for search criteria\n",
    "restaurant_name_query = input(\"Enter restaurant name to search: \")\n",
    "city_query = input(\"Enter city to search: \")\n",
    "cuisine_type_query = input(\"Enter cuisine type to search: \")\n",
    "\n",
    "# Run the query\n",
    "results = advanced_field_query(data, restaurant_name_query, city_query, cuisine_type_query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(data : pd.DataFrame )-> pd.DataFrame:\n",
    "    results = advanced_field_query(data, restaurant_name_query, city_query, cuisine_type_query)\n",
    "    price_range_filter = input(\"Enter price ranges to filter, separated by spaces (e.g., €, €€, €€€, €€€€): \").split()\n",
    "    region_filter = input(\"Enter regions to filter, separated by spaces: \").split()\n",
    "    region_filter = [region.title() for region in region_filter]\n",
    "    facilities_filter = input(\"Enter facilities/services to filter, separated by spaces: \").split()\n",
    "    facilities_filter = [facility.title() for facility in facilities_filter]\n",
    "    credit_cards_filter = input(\"Enter accepted credit cards to filter, separated by spaces: \").split()\n",
    "    credit_cards_filter = [card.title() for card in credit_cards_filter]\n",
    "    # apply the filters on data and display the results \n",
    "    filtered_data = data.loc[results.index,:]\n",
    "    if price_range_filter:\n",
    "        filtered_data = filtered_data[filtered_data['priceRange'].isin(price_range_filter)]\n",
    "    if region_filter:\n",
    "        filtered_data = filtered_data[filtered_data['region'].isin(region_filter)]\n",
    "    if facilities_filter:\n",
    "        filtered_data = filtered_data[filtered_data['facilitiesServices'].apply(lambda x: all(facility in x for facility in facilities_filter) if isinstance(x, str) else False)]\n",
    "        \n",
    "    if credit_cards_filter:\n",
    "        filtered_data = filtered_data[filtered_data['creditCards'].apply(lambda x: any(card in x for card in credit_cards_filter) if isinstance(x, str) else False)]\n",
    "\n",
    "    # Display the filtered results with the relevant columns\n",
    "    display_columns = filtered_data[['restaurantName', 'address', 'cuisineType', 'priceRange', 'website']]\n",
    "    return display_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_results \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m, in \u001b[0;36mfilter_results\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_results\u001b[39m(data : pd\u001b[38;5;241m.\u001b[39mDataFrame )\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43madvanced_field_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestaurant_name_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuisine_type_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     price_range_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter price ranges to filter, separated by spaces (e.g., €, €€, €€€, €€€€): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      4\u001b[0m     region_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter regions to filter, separated by spaces: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36madvanced_field_query\u001b[0;34m(data, restaurant_name_query, city_query, cuisine_type_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvanced_field_query\u001b[39m(data, restaurant_name_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, city_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, cuisine_type_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Create vocabularies and inverted indexes for each field\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     vocabularies, inverted_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_vocabularies_and_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Initialize results as a set of all document indices\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex)\n",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m, in \u001b[0;36mcreate_vocabularies_and_indexes\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m term_ids \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestaurantName\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisineType\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Loop through each restaurant document\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_id, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m():\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestaurantName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisineType\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     22\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m preprocess_text(row[field])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "filtered_results = filter_results(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Question (AQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "RUUURRRRUU\n",
      "NO\n",
      "YES\n",
      "RRRRUUU\n"
     ]
    }
   ],
   "source": [
    "def collect_packages(num_tests, test_cases):\n",
    "    outcomes = []\n",
    "\n",
    "    for case_index in range(num_tests):\n",
    "        num_packages, package_coords = test_cases[case_index]\n",
    "\n",
    "        # Sort packages by coordinates (x, y) to ensure the smallest lexicographical path\n",
    "        package_coords.sort()\n",
    "\n",
    "        path_steps = []\n",
    "        reachable = True\n",
    "        curr_x, curr_y = 0, 0  # Start at (0, 0)\n",
    "\n",
    "        for target_x, target_y in package_coords:\n",
    "            # Check if the package is reachable from the current position\n",
    "            if target_x < curr_x or target_y < curr_y:\n",
    "                # If any package requires moving left or down, mark as unreachable\n",
    "                reachable = False\n",
    "                break\n",
    "\n",
    "            # Append necessary moves to reach the target package\n",
    "            path_steps.append('R' * (target_x - curr_x))  # Move right\n",
    "            path_steps.append('U' * (target_y - curr_y))  # Move up\n",
    "\n",
    "            # Update the current position to the target package's coordinates\n",
    "            curr_x, curr_y = target_x, target_y\n",
    "\n",
    "        if reachable:\n",
    "            # If all packages are reachable, append \"YES\" and the path\n",
    "            outcomes.append(\"YES\\n\" + ''.join(path_steps))\n",
    "        else:\n",
    "            # If any package is unreachable, append \"NO\"\n",
    "            outcomes.append(\"NO\")\n",
    "\n",
    "    return outcomes\n",
    "\n",
    "# Sample input data\n",
    "num_tests = 3\n",
    "test_cases = [\n",
    "    (5, [(1, 3), (1, 2), (3, 3), (5, 5), (4, 3)]),\n",
    "    (2, [(1, 0), (0, 1)]),\n",
    "    (1, [(4, 3)])\n",
    "]\n",
    "\n",
    "# Execute function and print results\n",
    "results = collect_packages(num_tests, test_cases)\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for the Algorithm\n",
    "\n",
    "Given a list of packages located on a grid, where each package is represented by coordinates \\((x_i, y_i)\\), and a robot starting at \\((0, 0)\\) that can only move right (`R`) and up (`U`):\n",
    "\n",
    "1. **Input**:\n",
    "   - \\( t \\): the number of test cases.\n",
    "   - For each test case:\n",
    "      - \\( n \\): the number of packages.\n",
    "      - A list of \\( n \\) packages with coordinates \\((x_i, y_i)\\).\n",
    "\n",
    "2. **Algorithm**:\n",
    "Start\n",
    "\n",
    "    Function collect_packages(t, test_cases):\n",
    "        Results = []   // List to store results for each test case\n",
    "        \n",
    "        For each test_case in test_cases:\n",
    "            (n, packages) = test_case     // Extract number of packages and their coordinates\n",
    "            Sort packages in ascending order by x, then by y    // Lexicographical sorting\n",
    "\n",
    "            current_x = 0   // Initial robot position (0, 0)\n",
    "            current_y = 0\n",
    "            path = \"\"    // String to build the path\n",
    "            possible = True\n",
    "\n",
    "            For each (x, y) in packages:\n",
    "                If x < current_x or y < current_y:\n",
    "                    possible = False   // If the package is unreachable (backward movement)\n",
    "                    Break the loop\n",
    "\n",
    "                // Add the necessary moves to reach the package (x, y)\n",
    "                path = path + \"R\" * (x - current_x)  // Add right movements\n",
    "                path = path + \"U\" * (y - current_y)  // Add upward movements\n",
    "\n",
    "                // Update the robot's position\n",
    "                current_x = x\n",
    "                current_y = y\n",
    "\n",
    "            If possible:\n",
    "                Append \"YES\" and path to Results\n",
    "            Else:\n",
    "                Append \"NO\" to Results\n",
    "\n",
    "        Return Results   // Return results for all test cases\n",
    "\n",
    "    // Input reading\n",
    "    t = input()   // Number of test cases\n",
    "    test_cases = []   // List to store test cases\n",
    "\n",
    "    For i = 1 to t:\n",
    "        n = input()   // Number of packages\n",
    "        packages = []   // List to store package coordinates\n",
    "\n",
    "        For j = 1 to n:\n",
    "            x, y = input()   // Package coordinates\n",
    "            packages.append((x, y))   // Add the package to the list\n",
    "\n",
    "        Append (n, packages) to test_cases   // Add the test case to the list\n",
    "\n",
    "    // Call the function and print the results\n",
    "    results = collect_packages(t, test_cases)\n",
    "    For each result in results:\n",
    "        Print result\n",
    "\n",
    "End\n",
    "\n",
    "\n",
    "### Proof of Correctness\n",
    "\n",
    "1. **Sorting Ensures Lexicographical Order**:\n",
    "   - Sorting the packages by $x$ and then $y$-coordinates ensures that we attempt to collect packages in the lexicographically smallest way.\n",
    "   - If there is an accessible path for all packages after sorting, this path will be the smallest lexicographical path because it minimizes right and upward movements in order.\n",
    "\n",
    "2. **Reachability Check**:\n",
    "   - By moving only right or up from each position, we guarantee that any unreachable package (one that would require moving left or down) will be detected and skipped. The algorithm returns \"NO\" in such cases.\n",
    "\n",
    "3. **Path Construction**:\n",
    "   - For each reachable package, the algorithm appends the correct number of `R` and `U` moves, ensuring that the robot reaches each package in the required order.\n",
    "\n",
    "4. **Conclusion**:\n",
    "   - The algorithm is correct because it verifies reachability and constructs the smallest lexicographical path if possible.\n",
    "\n",
    "### Time Complexity Analysis\n",
    "\n",
    "1. **Sorting the Packages**:\n",
    "   - Sorting the list of $n$ packages takes $O (\\frac{n}{log(n)})$ time.\n",
    "\n",
    "2. **Constructing the Path**:\n",
    "   - The path is constructed by iterating over each package, which takes $O(n)$ time. For each package, we calculate the difference in coordinates and append the required moves.\n",
    "\n",
    "3. **Overall Complexity**:\n",
    "   - The sorting step, $O (\\frac{n}{log(n)})$, is the most time-consuming operation in the algorithm, making the overall complexity: $O (\\frac{n}{log(n)})$\n",
    "\n",
    "### Verification with a Language Model's Analysis\n",
    "\n",
    "If you asked a language model to evaluate this code, it would likely arrive at the same time complexity, $O (\\frac{n}{log(n)})$ because sorting is the dominant step in this approach. If there were any discrepancies, they would likely stem from misunderstanding the nature of appending moves as an $O(n)$ operation. However, given that sorting $n$ packages is indeed $O (\\frac{n}{log(n)})$ and dominates the time complexity, our analysis is accurate.\n",
    "\n",
    "### Extending the Problem: Robot Can Move Left or Down\n",
    "\n",
    "With the new rule allowing movement in all directions (right, left, up, down), we consider a **greedy algorithm** where the robot collects the closest package from its current location.\n",
    "\n",
    "#### Is the Greedy Algorithm Optimal?\n",
    "\n",
    "1. **Greedy Approach**:\n",
    "   - At each step, the robot moves to the closest package, defined by the Euclidean distance or Manhattan distance from the current position.\n",
    "   - The robot continues selecting the nearest uncollected package until all packages are collected.\n",
    "\n",
    "2. **Counterexample to Greedy Optimality**:\n",
    "   - The greedy approach does not guarantee the minimum path length for the following reason:\n",
    "   - **Example**:\n",
    "     - Suppose there are packages at $(0, 1)$, $(1, 0)$, and $(2, 2)$, and the robot starts at $(0, 0)$.\n",
    "     - The greedy approach would choose either $(0, 1)$ or $(1, 0)$ first, then the remaining one, and finally $(2, 2)$.\n",
    "     - However, the optimal path would be to go directly to $(2, 2)$ first, then collect $(0, 1)$ and $(1, 0)$, which would result in a shorter total path.\n",
    "\n",
    "3. **Conclusion**:\n",
    "   - The greedy algorithm is **not optimal** for minimizing the total distance. While it may be intuitive and yield a quick solution, it does not guarantee the shortest path because the closest package does not necessarily contribute to the globally shortest route for all packages.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
